{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfbyhs-xp9M_",
        "outputId": "6f725a9c-4e0d-4893-e939-b9cc67f15d43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPvmE2N2qVp7",
        "outputId": "781f7799-885a-46e9-dc2a-a68c87087be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PL\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/PL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu8J17eyqNCg",
        "outputId": "3f41ef5f-fc28-4475-b694-52417a2125b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=b8b83ced0d0e73cc5bde84ab0a121868dfda189c045e49e1d63e7fd4374b2783\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.25.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.12.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechpy\n",
            "  Downloading speechpy-2.4-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.7.3)\n",
            "Installing collected packages: speechpy\n",
            "Successfully installed speechpy-2.4\n"
          ]
        }
      ],
      "source": [
        "# !pip install cmath\n",
        "!pip install torch\n",
        "!pip install sklearn\n",
        "!pip install pandas\n",
        "!pip install librosa\n",
        "!pip install numpy\n",
        "!pip install speechpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43p2v4kztIcJ",
        "outputId": "616d1f21-8601-4764-e392-9c7155313599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein, jiwer\n",
            "Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyctcdecode\n",
            "  Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting pygtrie<3.0,>=2.1\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Collecting hypothesis<7,>=6.14\n",
            "  Downloading hypothesis-6.67.1-py3-none-any.whl (402 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from pyctcdecode) (1.21.6)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (22.2.0)\n",
            "Collecting exceptiongroup>=1.0.0\n",
            "  Downloading exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n",
            "Installing collected packages: pygtrie, exceptiongroup, hypothesis, pyctcdecode\n",
            "Successfully installed exceptiongroup-1.1.0 hypothesis-6.67.1 pyctcdecode-0.5.0 pygtrie-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyctcdecode.language_model:kenlm python bindings are not installed. Most likely you want to install it using: pip install https://github.com/kpu/kenlm/archive/master.zip\n",
            "WARNING:pyctcdecode.decoder:kenlm python bindings are not installed. Most likely you want to install it using: pip install https://github.com/kpu/kenlm/archive/master.zip\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install jiwer\n",
        "!pip install pyctcdecode\n",
        "from pyctcdecode import build_ctcdecoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkmstX7ujyi9"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import pandas as pd\n",
        "# data = pd.read_csv(\"/content/drive/MyDrive/PL/metadata_train.csv\")\n",
        "\n",
        "# train,test = train_test_split(data, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3dP8RlBkHuU"
      },
      "outputs": [],
      "source": [
        "# train.to_csv(\"/content/drive/MyDrive/PL/train.csv\")\n",
        "# test.to_csv(\"/content/drive/MyDrive/PL/dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sfQTy9LZqs6i"
      },
      "outputs": [],
      "source": [
        "from cmath import acos\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "# import numpy as np\n",
        "# from torch.utils.data import DataLoader\n",
        "# from infer import phonetic_embedding\n",
        "from help import Atention, wav_norm\n",
        "from char_embedding import tensor_to_text,text_to_tensor\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "# print(data['Wav_path'])\n",
        "sample = data.shape[0]\n",
        "# cols = ['Wav_path', 'Lyric_path']\n",
        "\n",
        "class MDD_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        acoustic_canonical = data\n",
        "        self.n_samples = sample\n",
        "        A = acoustic_canonical['Wav_path']\n",
        "        C = acoustic_canonical['Lyric_path']\n",
        "        B = acoustic_canonical['Lyric_path'] #output\n",
        "        \n",
        "\n",
        "        self.A_data = A \n",
        "        self.C_data = C\n",
        "        self.y_data = B \n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        p = self.A_data[index]\n",
        "        p = p.split(\".\")[0]\n",
        "        base_dir = '/content/drive/MyDrive/vocal_song_phonetic/'\n",
        "        p = p + str(\".npy\")\n",
        "        p = np.load(base_dir + str(p))\n",
        "        phonetic = torch.tensor(p)\n",
        "       \n",
        "        linguistic = text_to_tensor(self.C_data[index])\n",
        "        linguistic = torch.tensor(linguistic)\n",
        "        label = text_to_tensor(self.y_data[index])\n",
        "        label = torch.tensor(label)\n",
        "        return phonetic, linguistic, label\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "barzAew9tAev",
        "outputId": "cadad485-d0a7-4268-c9da-6ac0408dd4e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/content/drive/MyDrive/PL/linguistic_encoder.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, dtype=torch.float)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "51.90985808747225\n",
            "save 0\n",
            "0.4897156423346439\n",
            "1\n",
            "46.68650132502654\n",
            "save 1\n",
            "0.4404386917455334\n",
            "2\n",
            "45.365100795686025\n",
            "save 2\n",
            "0.4279726490159059\n",
            "3\n",
            "45.05404392687716\n",
            "save 3\n",
            "0.4250381502535581\n",
            "4\n",
            "44.694133905946735\n",
            "save 4\n",
            "0.4216427726976107\n",
            "5\n",
            "44.57325048917713\n",
            "save 5\n",
            "0.4205023631054446\n",
            "6\n",
            "44.29809137715863\n",
            "save 6\n",
            "0.4179065224260248\n",
            "7\n",
            "44.28136764063459\n",
            "save 7\n",
            "0.41774875132674144\n",
            "8\n",
            "44.18679456902086\n",
            "save 8\n",
            "0.41685655253793263\n",
            "9\n",
            "43.96395431707662\n",
            "save 9\n",
            "0.4147542860101568\n",
            "10\n",
            "43.76067376546919\n",
            "save 10\n",
            "0.4128365449572565\n",
            "11\n",
            "44.000565851975004\n",
            "12\n",
            "44.179314302305315\n",
            "13\n",
            "43.59082420376029\n",
            "save 13\n",
            "0.4112341906015122\n",
            "14\n",
            "43.599868162697874\n",
            "15\n",
            "43.330021766920616\n",
            "save 15\n",
            "0.4087737902539681\n",
            "16\n",
            "43.48002122245216\n",
            "17\n",
            "43.712386581049316\n",
            "18\n",
            "43.54815115994965\n",
            "19\n",
            "43.43260320076995\n",
            "20\n",
            "43.74174828257709\n",
            "21\n",
            "43.35992363368725\n",
            "22\n",
            "43.280467586419526\n",
            "save 22\n",
            "0.4083062979850899\n",
            "23\n",
            "43.26112317357824\n",
            "save 23\n",
            "0.40812380352432304\n",
            "24\n",
            "43.759810726054106\n",
            "25\n",
            "43.1824265399046\n",
            "save 25\n",
            "0.4073813824519302\n",
            "26\n",
            "43.808792786901556\n",
            "27\n",
            "43.35036258244608\n",
            "28\n",
            "43.55425549171284\n",
            "29\n",
            "43.49276242205124\n",
            "30\n",
            "43.29401460902201\n",
            "31\n",
            "43.14129662360092\n",
            "save 31\n",
            "0.4069933643735936\n",
            "32\n",
            "43.08291172134717\n",
            "save 32\n",
            "0.4064425634089356\n",
            "33\n",
            "43.062444822916966\n",
            "save 33\n",
            "0.4062494794614808\n",
            "34\n",
            "43.08635585070228\n",
            "35\n",
            "43.41735274415119\n",
            "36\n",
            "43.53565294347149\n",
            "37\n",
            "42.891188355432064\n",
            "save 37\n",
            "0.4046338524097364\n",
            "38\n",
            "43.15548780126493\n",
            "39\n",
            "43.16040303703973\n",
            "40\n",
            "42.66050585763798\n",
            "save 40\n",
            "0.40245760243054696\n",
            "41\n",
            "43.23010980211507\n",
            "42\n",
            "42.93495351075062\n",
            "43\n",
            "43.4637772261502\n",
            "44\n",
            "42.91679815283506\n",
            "45\n",
            "42.83753669663203\n",
            "46\n",
            "42.55049217878393\n",
            "save 46\n",
            "0.40141973753569743\n",
            "47\n",
            "42.698366612553585\n",
            "48\n",
            "42.855667485673095\n",
            "49\n",
            "43.17565211862319\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# from model import Net\n",
        "# from cProfile import label\n",
        "# from infer import phonetic_embedding\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from phonetic_encoder import Phonetic_encoder\n",
        "from acoustic_encoder import Acoustic_encoder\n",
        "from linguistic_encoder import Linguistic_encoder\n",
        "from char_embedding import text_to_tensor, clean_corpus\n",
        "from help import wav_norm, Atention\n",
        "import numpy as np\n",
        "# from help import beam_search_decoding\n",
        "from model import Acoustic_Phonetic_Linguistic\n",
        "# from dataloader import MDD_Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from jiwer import wer, cer\n",
        "tokenizer = Wav2Vec2Processor.from_pretrained(\"pretrained_finetuned\")\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "f = open(\"/content/drive/MyDrive/PL/vocal_loss.txt\", 'a')\n",
        "MDD = MDD_Dataset()\n",
        "# print(data)\n",
        "net = Acoustic_Phonetic_Linguistic()\n",
        "net.to('cuda')\n",
        "\n",
        "dev = pd.read_csv(\"dev.csv\")\n",
        "# net = torch.load('/content/drive/MyDrive/PL/raw_checkpoint.pth14')\n",
        "# net = net.to('cpu')\n",
        "train_loader = DataLoader(dataset=MDD,\n",
        "                          batch_size=1,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "\n",
        "\n",
        "ctc_loss = nn.CTCLoss(blank = 95)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
        "optimizer = optim.AdamW(net.parameters(), lr = 0.00001)\n",
        "# optimizer = optim.SGD(net.parameters(), 0.01, momentum = 0.9)\n",
        "# optimizer = torch.load('/home/tuht/train_wav2vec/MDD_Checkpoint/checkpoint_optim.pth')\n",
        "best_WER = 100\n",
        "for epoch in range(50):  # loop over the dataset multiple times\n",
        "    net.train().to('cuda')\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        phonetic, linguistic, labels = data\n",
        "        # acoustic = torch.tensor(0).to('cuda')\n",
        "        phonetic = phonetic.to('cuda')\n",
        "        linguistic = linguistic.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(phonetic, linguistic)\n",
        "        outputs = outputs.unsqueeze(1)\n",
        "        input_lengths = outputs.shape\n",
        "        target_lengths = labels.shape\n",
        "        target = labels\n",
        "        input_lengths = [input_lengths[0]]\n",
        "        target_lengths =[target_lengths[1]]\n",
        "        input_lengths = torch.tensor(input_lengths)\n",
        "        target_lengths = torch.tensor(target_lengths)\n",
        "        outputs = (F.log_softmax(outputs, dim=2))\n",
        "        loss = ctc_loss(outputs, labels, input_lengths, target_lengths)\n",
        "        # print(i)\n",
        "        # print(loss)\n",
        "        f.write(\"(\" +str(epoch) + \",\" + str(i) + \")\" + \"  loss: \" + str(loss) + \"\\n\") \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    WER = 0\n",
        "    net.eval().to('cuda')\n",
        "    for i in range(len(dev)):\n",
        "        p = dev['Wav_path'][i]\n",
        "        p = p.split(\".\")[0]\n",
        "        base_dir = '/content/drive/MyDrive/vocal_song_phonetic/'\n",
        "        p = p + str(\".npy\")\n",
        "        p = np.load(base_dir + str(p))\n",
        "        phonetic = torch.tensor(p)\n",
        "       \n",
        "        linguistic = text_to_tensor(dev['Lyric_path'][i])\n",
        "        linguistic = torch.tensor(linguistic)\n",
        "        label = text_to_tensor(dev['Lyric_path'][i])\n",
        "        label = torch.tensor(label)\n",
        "        phonetic = phonetic.to('cuda')\n",
        "        linguistic = linguistic.to('cuda')\n",
        "        phonetic = phonetic.unsqueeze(0)\n",
        "        linguistic = linguistic.unsqueeze(0)\n",
        "        outputs = net(phonetic, linguistic)\n",
        "        outputs = outputs.unsqueeze(0)\n",
        "        x = F.log_softmax(outputs,dim=2)\n",
        "        labels = ['ắ', 'ồ', 'z', 'ứ', 'ỡ', 'ì', 'x', 'ặ', 'u', 'ẹ', 'd', 'ỵ', 'r', 'p', 't', 'ỳ', 'ẩ', 'f', 'ó', 'á', 'v', 'ã', 'i', 'ư', 'ở', 'ễ', 'ụ', 'ú', 'ũ', ' ', 'ă', 'é', 'ằ', 'a', 'ấ', 'ờ', 'ữ', 'ớ', 'n', 'ý', 's', 'h', 'ơ', 'ị', 'l', 'c', 'k', 'ỷ', 'ỗ', 'ế', 'ẻ', 'ợ', 'ẫ', 'í', 'ỏ', 'ủ', 'g', 'q', 'j', 'ò', 'ỹ', 'ự', 'ô', 'b', 'y', 'ĩ', 'ỉ', 'ẵ', 'ầ', 'ê', 'ộ', 'ậ', 'm', 'ń', 'o', 'ọ', 'đ', 'ẽ', 'ử', 'à', 'è', 'e', 'ẳ', 'ổ', 'ù', 'w', 'ả', 'ạ', 'â', 'ệ', 'ề', 'õ', 'ố', 'ể', 'ừ',]\n",
        "        x = x.detach().cpu().numpy()\n",
        "        decoder = build_ctcdecoder(\n",
        "            labels = labels,\n",
        "            \n",
        "        )\n",
        "        x = x.squeeze(0)\n",
        "        ground_truth = (clean_corpus(dev['Lyric_path'][i]))\n",
        "        hypothesis = str(decoder.decode(x))\n",
        "        error = cer(ground_truth, hypothesis)\n",
        "        WER = WER + error\n",
        "    print(epoch)\n",
        "    print(WER)\n",
        "    if WER/len(dev)<best_WER:\n",
        "      print(\"save \" + str(epoch))\n",
        "      # print(epoch)\n",
        "      # print(WER)\n",
        "      best_WER = WER/len(dev)\n",
        "      print(best_WER)\n",
        "      torch.save(net, '/content/drive/MyDrive/PL/MDD_Checkpoint/vocal_checkpoint.pth')\n",
        "        \n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyuzEBmSLO4U",
        "outputId": "0a2c2413-4433-4a59-a1e0-af9388352911"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "96.42511009903221\n",
            "save 0\n",
            "0.9096708499908699\n",
            "1\n",
            "61.9815346063328\n",
            "save 1\n",
            "0.5847314585503094\n",
            "2\n",
            "46.05965181762243\n",
            "save 2\n",
            "0.4345250171473814\n",
            "3\n",
            "44.414971797417316\n",
            "save 3\n",
            "0.41900916790016335\n",
            "4\n",
            "44.478555915441774\n",
            "5\n",
            "44.56808397596326\n",
            "6\n",
            "43.85708390496426\n",
            "save 6\n",
            "0.41374607457513457\n",
            "7\n",
            "43.95150678645302\n",
            "8\n",
            "43.493756910568614\n",
            "save 8\n",
            "0.41031846142045864\n",
            "9\n",
            "44.050779141265295\n",
            "10\n",
            "44.035797826556355\n",
            "11\n",
            "43.700854789003586\n",
            "12\n",
            "43.455871197254545\n",
            "save 12\n",
            "0.40996104903070324\n",
            "13\n",
            "43.13841063541566\n",
            "save 13\n",
            "0.40696613806995907\n",
            "14\n",
            "43.3725868077413\n",
            "15\n",
            "43.4991077183926\n",
            "16\n",
            "43.51695331266012\n",
            "17\n",
            "44.23127775713887\n",
            "18\n",
            "43.305247410720874\n",
            "19\n",
            "43.2743587913094\n",
            "20\n",
            "43.016474484435\n",
            "save 20\n",
            "0.4058157970229717\n",
            "21\n",
            "43.13909512578376\n",
            "22\n",
            "43.34982950452361\n",
            "23\n",
            "43.45967200982931\n",
            "24\n",
            "43.41360431241227\n",
            "25\n",
            "43.20079826454078\n",
            "26\n",
            "43.52682939369963\n",
            "27\n",
            "43.23118431335593\n",
            "28\n",
            "43.72664369434233\n",
            "29\n",
            "43.136805792270096\n",
            "30\n",
            "43.53556120199259\n",
            "31\n",
            "43.61503763531481\n",
            "32\n",
            "43.37154670457896\n",
            "33\n",
            "43.904638832338044\n",
            "34\n",
            "43.065003333976186\n",
            "35\n",
            "42.66899642390817\n",
            "save 35\n",
            "0.4025377021123412\n",
            "36\n",
            "43.02308147963642\n",
            "37\n",
            "43.06459578249432\n",
            "38\n",
            "42.90584353416534\n",
            "39\n",
            "43.0468739780298\n",
            "40\n",
            "43.31512784845694\n",
            "41\n",
            "43.5932050664944\n",
            "42\n",
            "43.52931648541204\n",
            "43\n",
            "43.22931291465098\n",
            "44\n",
            "43.253079608224446\n",
            "45\n",
            "43.30744716092536\n",
            "46\n",
            "43.738334801705015\n",
            "47\n",
            "43.321557875991594\n",
            "48\n",
            "43.51982772596302\n",
            "49\n",
            "43.1996503358323\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# from model import Net\n",
        "# from cProfile import label\n",
        "# from infer import phonetic_embedding\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from phonetic_encoder import Phonetic_encoder\n",
        "from acoustic_encoder import Acoustic_encoder\n",
        "from linguistic_encoder import Linguistic_encoder\n",
        "from char_embedding import text_to_tensor, clean_corpus\n",
        "from help import wav_norm, Atention\n",
        "import numpy as np\n",
        "# from help import beam_search_decoding\n",
        "from model import Acoustic_Phonetic_Linguistic, Phonetic_Only\n",
        "# from dataloader import MDD_Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from jiwer import wer, cer\n",
        "tokenizer = Wav2Vec2Processor.from_pretrained(\"pretrained_finetuned\")\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "f = open(\"/content/drive/MyDrive/PL/vocal_loss.txt\", 'a')\n",
        "MDD = MDD_Dataset()\n",
        "# print(data)\n",
        "net = Phonetic_Only()\n",
        "net.to('cuda')\n",
        "\n",
        "dev = pd.read_csv(\"dev.csv\")\n",
        "# net = torch.load('/content/drive/MyDrive/PL/raw_checkpoint.pth14')\n",
        "# net = net.to('cpu')\n",
        "train_loader = DataLoader(dataset=MDD,\n",
        "                          batch_size=1,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "\n",
        "\n",
        "ctc_loss = nn.CTCLoss(blank = 95)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
        "optimizer = optim.AdamW(net.parameters(), lr = 0.001)\n",
        "# optimizer = optim.SGD(net.parameters(), 0.01, momentum = 0.9)\n",
        "# optimizer = torch.load('/home/tuht/train_wav2vec/MDD_Checkpoint/checkpoint_optim.pth')\n",
        "best_WER = 100\n",
        "for epoch in range(50):  # loop over the dataset multiple times\n",
        "    net.train().to('cuda')\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        phonetic, linguistic, labels = data\n",
        "        # acoustic = torch.tensor(0).to('cuda')\n",
        "        phonetic = phonetic.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(phonetic)\n",
        "        outputs = outputs.unsqueeze(1)\n",
        "        input_lengths = outputs.shape\n",
        "        target_lengths = labels.shape\n",
        "        target = labels\n",
        "        input_lengths = [input_lengths[0]]\n",
        "        target_lengths =[target_lengths[1]]\n",
        "        input_lengths = torch.tensor(input_lengths)\n",
        "        target_lengths = torch.tensor(target_lengths)\n",
        "        outputs = (F.log_softmax(outputs, dim=2))\n",
        "        loss = ctc_loss(outputs, labels, input_lengths, target_lengths)\n",
        "        # print(i)\n",
        "        # print(loss)\n",
        "        f.write(\"(\" +str(epoch) + \",\" + str(i) + \")\" + \"  loss: \" + str(loss) + \"\\n\") \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    WER = 0\n",
        "    net.eval().to('cuda')\n",
        "    for i in range(len(dev)):\n",
        "        p = dev['Wav_path'][i]\n",
        "        p = p.split(\".\")[0]\n",
        "        base_dir = '/content/drive/MyDrive/vocal_song_phonetic/'\n",
        "        p = p + str(\".npy\")\n",
        "        p = np.load(base_dir + str(p))\n",
        "        phonetic = torch.tensor(p).to('cuda')\n",
        "        phonetic = phonetic.unsqueeze(0)\n",
        "        outputs = net(phonetic)\n",
        "        outputs = outputs.unsqueeze(0)\n",
        "        x = F.log_softmax(outputs,dim=2)\n",
        "        labels = ['ắ', 'ồ', 'z', 'ứ', 'ỡ', 'ì', 'x', 'ặ', 'u', 'ẹ', 'd', 'ỵ', 'r', 'p', 't', 'ỳ', 'ẩ', 'f', 'ó', 'á', 'v', 'ã', 'i', 'ư', 'ở', 'ễ', 'ụ', 'ú', 'ũ', ' ', 'ă', 'é', 'ằ', 'a', 'ấ', 'ờ', 'ữ', 'ớ', 'n', 'ý', 's', 'h', 'ơ', 'ị', 'l', 'c', 'k', 'ỷ', 'ỗ', 'ế', 'ẻ', 'ợ', 'ẫ', 'í', 'ỏ', 'ủ', 'g', 'q', 'j', 'ò', 'ỹ', 'ự', 'ô', 'b', 'y', 'ĩ', 'ỉ', 'ẵ', 'ầ', 'ê', 'ộ', 'ậ', 'm', 'ń', 'o', 'ọ', 'đ', 'ẽ', 'ử', 'à', 'è', 'e', 'ẳ', 'ổ', 'ù', 'w', 'ả', 'ạ', 'â', 'ệ', 'ề', 'õ', 'ố', 'ể', 'ừ',]\n",
        "        x = x.detach().cpu().numpy()\n",
        "        decoder = build_ctcdecoder(\n",
        "            labels = labels,\n",
        "            \n",
        "        )\n",
        "        x = x.squeeze(0)\n",
        "        ground_truth = (clean_corpus(dev['Lyric_path'][i]))\n",
        "        hypothesis = str(decoder.decode(x))\n",
        "        error = cer(ground_truth, hypothesis)\n",
        "        WER = WER + error\n",
        "    print(epoch)\n",
        "    print(WER)\n",
        "    if WER/len(dev)<best_WER:\n",
        "      print(\"save \" + str(epoch))\n",
        "      # print(epoch)\n",
        "      # print(WER)\n",
        "      best_WER = WER/len(dev)\n",
        "      print(best_WER)\n",
        "      torch.save(net, '/content/drive/MyDrive/PL/MDD_Checkpoint/no_linguistic_vocal_checkpoint.pth')\n",
        "        \n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "2R9vgdedvmAS",
        "outputId": "ea48ec30-4740-4b1b-cee7-009528ccf1ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\npath = '/content/37303234365f3231.wav'\\nlyrics = 'Trăngcôđơnlặnglẽ Nhớaiquatừng Gócphốngàyxưa Nghetrongtimvụnvỡ Baolầnnáttanvìai Cóainhớngày Xưaemơi Giờđãxatôimấtrồi Ánhtrăngsáng Lònganhemơi Giờthấmướt'\\nphonetic = phonetic_embedding(path).squeeze(0)\\nlinguistic = text_to_tensor(lyrics)\\nlinguistic = torch.tensor(linguistic)\\nlabel = text_to_tensor(dev['Lyric_path'][i])\\nlabel = torch.tensor(label)\\nphonetic = phonetic.to('cuda')\\nlinguistic = linguistic.to('cuda')\\nphonetic = phonetic.unsqueeze(0)\\nlinguistic = linguistic.unsqueeze(0)\\noutputs = net(phonetic, linguistic)\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Eval\n",
        "# from infer import phonetic_embedding\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from phonetic_encoder import Phonetic_encoder\n",
        "from acoustic_encoder import Acoustic_encoder\n",
        "from linguistic_encoder import Linguistic_encoder\n",
        "from char_embedding import text_to_tensor, clean_corpus\n",
        "from help import wav_norm, Atention\n",
        "import numpy as np\n",
        "# from help import beam_search_decoding\n",
        "from model import Acoustic_Phonetic_Linguistic\n",
        "# from dataloader import MDD_Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from jiwer import wer, cer\n",
        "tokenizer = Wav2Vec2Processor.from_pretrained(\"pretrained_finetuned\")\n",
        "\n",
        "from infer import phonetic_embedding\n",
        "net = Acoustic_Phonetic_Linguistic()\n",
        "net.to('cuda')\n",
        "net = torch.load('/content/drive/MyDrive/PL/MDD_Checkpoint/vocal_checkpoint.pth')\n",
        "net.eval().to('cuda')\n",
        "\n",
        "\"\"\"\n",
        "path = '/content/37303234365f3231.wav'\n",
        "lyrics = 'Trăngcôđơnlặnglẽ Nhớaiquatừng Gócphốngàyxưa Nghetrongtimvụnvỡ Baolầnnáttanvìai Cóainhớngày Xưaemơi Giờđãxatôimấtrồi Ánhtrăngsáng Lònganhemơi Giờthấmướt'\n",
        "phonetic = phonetic_embedding(path).squeeze(0)\n",
        "linguistic = text_to_tensor(lyrics)\n",
        "linguistic = torch.tensor(linguistic)\n",
        "label = text_to_tensor(dev['Lyric_path'][i])\n",
        "label = torch.tensor(label)\n",
        "phonetic = phonetic.to('cuda')\n",
        "linguistic = linguistic.to('cuda')\n",
        "phonetic = phonetic.unsqueeze(0)\n",
        "linguistic = linguistic.unsqueeze(0)\n",
        "outputs = net(phonetic, linguistic)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAwOMiqfR3m5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def clean_corpus(str1):\n",
        "    res1 = \"\"\n",
        "    for i in str1:\n",
        "        if i.isalpha() or i==\" \":\n",
        "            res1 = \"\".join([res1, i])\n",
        "    return res1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvw8FCR6Ropu",
        "outputId": "6b570580-19d1-4187-fa94-af2a5ad62af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(870, 96)\n",
            "(1210, 96)\n",
            "(1394, 96)\n",
            "(1302, 96)\n",
            "(549, 96)\n",
            "(779, 96)\n",
            "(638, 96)\n",
            "(1296, 96)\n",
            "(454, 96)\n",
            "(1053, 96)\n",
            "(787, 96)\n",
            "(666, 96)\n",
            "(539, 96)\n",
            "(690, 96)\n",
            "(1187, 96)\n",
            "(1283, 96)\n",
            "(1155, 96)\n",
            "(595, 96)\n",
            "(1032, 96)\n",
            "(449, 96)\n",
            "(1291, 96)\n",
            "(1108, 96)\n",
            "(1310, 96)\n",
            "(1054, 96)\n",
            "(1089, 96)\n",
            "(1255, 96)\n",
            "(923, 96)\n",
            "(1271, 96)\n",
            "(1138, 96)\n",
            "(1140, 96)\n",
            "(781, 96)\n",
            "(735, 96)\n",
            "(738, 96)\n",
            "(489, 96)\n",
            "(1119, 96)\n",
            "(749, 96)\n",
            "(949, 96)\n",
            "(648, 96)\n",
            "(863, 96)\n",
            "(827, 96)\n",
            "(855, 96)\n",
            "(1313, 96)\n",
            "(840, 96)\n",
            "(979, 96)\n",
            "(641, 96)\n",
            "(1193, 96)\n",
            "(744, 96)\n",
            "(1171, 96)\n",
            "(943, 96)\n",
            "(1456, 96)\n",
            "(667, 96)\n",
            "(976, 96)\n",
            "(1028, 96)\n",
            "(1358, 96)\n",
            "(1147, 96)\n",
            "(1402, 96)\n",
            "(1148, 96)\n",
            "(555, 96)\n",
            "(1191, 96)\n",
            "(827, 96)\n",
            "(509, 96)\n",
            "(786, 96)\n",
            "(1084, 96)\n",
            "(1399, 96)\n",
            "(1048, 96)\n",
            "(1144, 96)\n",
            "(926, 96)\n",
            "(617, 96)\n",
            "(538, 96)\n",
            "(488, 96)\n",
            "(715, 96)\n",
            "(887, 96)\n",
            "(1194, 96)\n",
            "(810, 96)\n",
            "(1390, 96)\n",
            "(551, 96)\n",
            "(939, 96)\n",
            "(1337, 96)\n",
            "(606, 96)\n",
            "(1088, 96)\n",
            "(891, 96)\n",
            "(1154, 96)\n",
            "(502, 96)\n",
            "(1294, 96)\n",
            "(1296, 96)\n",
            "(1299, 96)\n",
            "(343, 96)\n",
            "(775, 96)\n",
            "(1320, 96)\n",
            "(1344, 96)\n",
            "(1054, 96)\n",
            "(1458, 96)\n",
            "(1142, 96)\n",
            "(1162, 96)\n",
            "(1244, 96)\n",
            "(1377, 96)\n",
            "(1052, 96)\n",
            "(1057, 96)\n",
            "(1088, 96)\n",
            "(288, 96)\n",
            "(1099, 96)\n",
            "(1309, 96)\n",
            "(1075, 96)\n",
            "(857, 96)\n",
            "(1124, 96)\n",
            "(1169, 96)\n",
            "(1244, 96)\n",
            "(1449, 96)\n",
            "(1481, 96)\n",
            "(451, 96)\n",
            "(1428, 96)\n",
            "(1345, 96)\n",
            "(1412, 96)\n",
            "(700, 96)\n",
            "(1065, 96)\n",
            "(800, 96)\n",
            "(895, 96)\n",
            "(1492, 96)\n",
            "(1409, 96)\n",
            "(1473, 96)\n",
            "(1077, 96)\n",
            "(794, 96)\n",
            "(1310, 96)\n",
            "(462, 96)\n",
            "(1282, 96)\n",
            "(1078, 96)\n",
            "(438, 96)\n",
            "(1272, 96)\n",
            "(1164, 96)\n",
            "(756, 96)\n",
            "(951, 96)\n",
            "(522, 96)\n",
            "(441, 96)\n",
            "(914, 96)\n",
            "(1115, 96)\n",
            "(1160, 96)\n",
            "(1103, 96)\n",
            "(500, 96)\n",
            "(1217, 96)\n",
            "(1105, 96)\n",
            "(484, 96)\n",
            "(1318, 96)\n",
            "(1444, 96)\n",
            "(914, 96)\n",
            "(993, 96)\n",
            "(1481, 96)\n",
            "(1011, 96)\n",
            "(472, 96)\n",
            "(745, 96)\n",
            "(1404, 96)\n",
            "(968, 96)\n",
            "(347, 96)\n",
            "(1034, 96)\n",
            "(1112, 96)\n",
            "(1204, 96)\n",
            "(977, 96)\n",
            "(981, 96)\n",
            "(1132, 96)\n",
            "(1169, 96)\n",
            "(1007, 96)\n",
            "(1076, 96)\n",
            "(1021, 96)\n",
            "(652, 96)\n",
            "(852, 96)\n",
            "(712, 96)\n",
            "(1496, 96)\n",
            "(932, 96)\n",
            "(1159, 96)\n",
            "(1103, 96)\n",
            "(1145, 96)\n",
            "(250, 96)\n",
            "(1217, 96)\n",
            "(929, 96)\n",
            "(882, 96)\n",
            "(521, 96)\n",
            "(1336, 96)\n",
            "(598, 96)\n",
            "(1344, 96)\n",
            "(1202, 96)\n",
            "(520, 96)\n",
            "(1105, 96)\n",
            "(1255, 96)\n",
            "(1416, 96)\n",
            "(687, 96)\n",
            "(1034, 96)\n",
            "(1298, 96)\n",
            "(1200, 96)\n",
            "(686, 96)\n",
            "(890, 96)\n",
            "(620, 96)\n",
            "(950, 96)\n",
            "(1446, 96)\n",
            "(1110, 96)\n",
            "(1103, 96)\n",
            "(707, 96)\n",
            "(1413, 96)\n",
            "(941, 96)\n",
            "(1165, 96)\n",
            "(690, 96)\n",
            "(598, 96)\n",
            "(1151, 96)\n",
            "(1074, 96)\n",
            "(1136, 96)\n",
            "(892, 96)\n",
            "(707, 96)\n",
            "(853, 96)\n",
            "(1125, 96)\n",
            "(677, 96)\n",
            "(1017, 96)\n",
            "(836, 96)\n",
            "(1127, 96)\n",
            "(695, 96)\n",
            "(903, 96)\n",
            "(781, 96)\n",
            "(906, 96)\n",
            "(981, 96)\n",
            "(1297, 96)\n",
            "(1454, 96)\n",
            "(1211, 96)\n",
            "(893, 96)\n",
            "(1025, 96)\n",
            "(736, 96)\n",
            "(1204, 96)\n",
            "(1067, 96)\n",
            "(1310, 96)\n",
            "(1138, 96)\n",
            "(1136, 96)\n",
            "(1329, 96)\n",
            "(518, 96)\n",
            "(456, 96)\n",
            "(840, 96)\n",
            "(496, 96)\n",
            "(651, 96)\n",
            "(626, 96)\n",
            "(861, 96)\n",
            "(1236, 96)\n",
            "(1108, 96)\n",
            "(1080, 96)\n",
            "(1093, 96)\n",
            "(1409, 96)\n",
            "(1312, 96)\n",
            "(1401, 96)\n",
            "(1284, 96)\n",
            "(861, 96)\n",
            "(514, 96)\n",
            "(1016, 96)\n",
            "(756, 96)\n",
            "(1318, 96)\n",
            "(305, 96)\n",
            "(628, 96)\n",
            "(564, 96)\n",
            "(493, 96)\n",
            "(995, 96)\n",
            "(655, 96)\n",
            "(1431, 96)\n",
            "(897, 96)\n",
            "(1370, 96)\n",
            "(1125, 96)\n",
            "(1451, 96)\n",
            "(601, 96)\n",
            "(1340, 96)\n",
            "(730, 96)\n",
            "(828, 96)\n",
            "(1357, 96)\n"
          ]
        }
      ],
      "source": [
        "public_test = pd.read_csv(\"public_test.csv\")\n",
        "for i in range(len(public_test)):\n",
        "  path = public_test['Wav_path'][i]\n",
        "  path = path.split(\"/\")[5].split(\".\")[0]\n",
        "  lyrics = public_test['Lyric_path'][i]\n",
        "  phonetic = phonetic_embedding('/content/drive/MyDrive/public_test/songs/' + path + \".wav\").squeeze(0)\n",
        "  # phonetic = np.load('/content/drive/MyDrive/vocal_public_test/' + path + \".npy\")\n",
        "  linguistic = text_to_tensor(lyrics)\n",
        "  linguistic = torch.tensor(linguistic)\n",
        "\n",
        "  phonetic = phonetic.to('cuda')\n",
        "  linguistic = linguistic.to('cuda')\n",
        "  phonetic = phonetic.unsqueeze(0)\n",
        "  linguistic = linguistic.unsqueeze(0)\n",
        "  outputs = net(phonetic, linguistic).detach().cpu().numpy()\n",
        "  np.save(\"/content/drive/MyDrive/song_phonetic/\" + path + \".npy\", outputs)\n",
        "  print(outputs.shape)\n",
        "\n",
        "# path = '/content/37303234365f3231.wav'\n",
        "# lyrics = 'Trăngcôđơnlặnglẽ Nhớaiquatừng Gócphốngàyxưa Nghetrongtimvụnvỡ Baolầnnáttanvìai Cóainhớngày Xưaemơi Giờđãxatôimấtrồi Ánhtrăngsáng Lònganhemơi Giờthấmướt'\n",
        "# phonetic = phonetic_embedding(path).squeeze(0)\n",
        "# linguistic = text_to_tensor(lyrics)\n",
        "# linguistic = torch.tensor(linguistic)\n",
        "# label = text_to_tensor(dev['Lyric_path'][i])\n",
        "# label = torch.tensor(label)\n",
        "# phonetic = phonetic.to('cuda')\n",
        "# linguistic = linguistic.to('cuda')\n",
        "# phonetic = phonetic.unsqueeze(0)\n",
        "# linguistic = linguistic.unsqueeze(0)\n",
        "# outputs = net(phonetic, linguistic)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eval\n",
        "# from infer import phonetic_embedding\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from phonetic_encoder import Phonetic_encoder\n",
        "from acoustic_encoder import Acoustic_encoder\n",
        "from linguistic_encoder import Linguistic_encoder\n",
        "from char_embedding import text_to_tensor, clean_corpus\n",
        "from help import wav_norm, Atention\n",
        "import numpy as np\n",
        "# from help import beam_search_decoding\n",
        "from model import Acoustic_Phonetic_Linguistic, Phonetic_Only\n",
        "# from dataloader import MDD_Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from jiwer import wer, cer\n",
        "tokenizer = Wav2Vec2Processor.from_pretrained(\"pretrained_finetuned\")\n",
        "\n",
        "from infer import phonetic_embedding\n",
        "net = Phonetic_Only()\n",
        "net.to('cuda')\n",
        "net = torch.load('/content/drive/MyDrive/PL/MDD_Checkpoint/no_linguistic_vocal_checkpoint.pth')\n",
        "net.eval().to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7idd-JUgshqE",
        "outputId": "211393eb-bfad-4f04-b69f-716f6d875d0d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py:375: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Phonetic_Only(\n",
              "  (Phonetic_encoder): Phonetic_encoder(\n",
              "    (CNN): CNN_Stack(\n",
              "      (Conv2d): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (reLU): ReLU()\n",
              "      (drop_out): Dropout(p=0.2, inplace=False)\n",
              "      (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (RNN): RNN_Stack(\n",
              "      (reLU): ReLU()\n",
              "      (drop_out): Dropout(p=0.2, inplace=False)\n",
              "      (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bilstm): LSTM(768, 384, bidirectional=True)\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=96, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_test = pd.read_csv(\"public_test.csv\")\n",
        "for i in range(len(public_test)):\n",
        "  path = public_test['Wav_path'][i]\n",
        "  path = path.split(\"/\")[5].split(\".\")[0]\n",
        "  lyrics = public_test['Lyric_path'][i]\n",
        "  phonetic = phonetic_embedding('/content/drive/MyDrive/vocal_public_test/' + path + \".wav\").squeeze(0)\n",
        "\n",
        "\n",
        "  phonetic = phonetic.to('cuda')\n",
        "\n",
        "  phonetic = phonetic.unsqueeze(0)\n",
        "\n",
        "  outputs = net(phonetic).detach().cpu().numpy()\n",
        "  np.save(\"/content/drive/MyDrive/vocal_no_linguistic/\" + path + \".npy\", outputs)\n",
        "  print(outputs.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aiouXQJszBq",
        "outputId": "62b6dc4f-d942-4a0d-9d3a-b8dc254a4682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(869, 96)\n",
            "(1209, 96)\n",
            "(1394, 96)\n",
            "(1302, 96)\n",
            "(548, 96)\n",
            "(778, 96)\n",
            "(638, 96)\n",
            "(1295, 96)\n",
            "(453, 96)\n",
            "(1052, 96)\n",
            "(786, 96)\n",
            "(666, 96)\n",
            "(538, 96)\n",
            "(689, 96)\n",
            "(1186, 96)\n",
            "(1282, 96)\n",
            "(1154, 96)\n",
            "(594, 96)\n",
            "(1031, 96)\n",
            "(449, 96)\n",
            "(1290, 96)\n",
            "(1108, 96)\n",
            "(1309, 96)\n",
            "(1053, 96)\n",
            "(1088, 96)\n",
            "(1254, 96)\n",
            "(922, 96)\n",
            "(1271, 96)\n",
            "(1138, 96)\n",
            "(1139, 96)\n",
            "(781, 96)\n",
            "(735, 96)\n",
            "(738, 96)\n",
            "(488, 96)\n",
            "(1118, 96)\n",
            "(748, 96)\n",
            "(948, 96)\n",
            "(648, 96)\n",
            "(862, 96)\n",
            "(826, 96)\n",
            "(854, 96)\n",
            "(1312, 96)\n",
            "(839, 96)\n",
            "(979, 96)\n",
            "(640, 96)\n",
            "(1193, 96)\n",
            "(743, 96)\n",
            "(1171, 96)\n",
            "(942, 96)\n",
            "(1456, 96)\n",
            "(667, 96)\n",
            "(976, 96)\n",
            "(1028, 96)\n",
            "(1358, 96)\n",
            "(1146, 96)\n",
            "(1401, 96)\n",
            "(1147, 96)\n",
            "(554, 96)\n",
            "(1190, 96)\n",
            "(827, 96)\n",
            "(508, 96)\n",
            "(785, 96)\n",
            "(1084, 96)\n",
            "(1398, 96)\n",
            "(1048, 96)\n",
            "(1143, 96)\n",
            "(926, 96)\n",
            "(617, 96)\n",
            "(538, 96)\n",
            "(487, 96)\n",
            "(714, 96)\n",
            "(886, 96)\n",
            "(1193, 96)\n",
            "(810, 96)\n",
            "(1389, 96)\n",
            "(550, 96)\n",
            "(939, 96)\n",
            "(1337, 96)\n",
            "(605, 96)\n",
            "(1087, 96)\n",
            "(890, 96)\n",
            "(1153, 96)\n",
            "(501, 96)\n",
            "(1294, 96)\n",
            "(1295, 96)\n",
            "(1298, 96)\n",
            "(343, 96)\n",
            "(774, 96)\n",
            "(1319, 96)\n",
            "(1343, 96)\n",
            "(1053, 96)\n",
            "(1457, 96)\n",
            "(1142, 96)\n",
            "(1161, 96)\n",
            "(1244, 96)\n",
            "(1376, 96)\n",
            "(1051, 96)\n",
            "(1056, 96)\n",
            "(1088, 96)\n",
            "(287, 96)\n",
            "(1099, 96)\n",
            "(1308, 96)\n",
            "(1074, 96)\n",
            "(856, 96)\n",
            "(1123, 96)\n",
            "(1168, 96)\n",
            "(1244, 96)\n",
            "(1448, 96)\n",
            "(1481, 96)\n",
            "(450, 96)\n",
            "(1427, 96)\n",
            "(1345, 96)\n",
            "(1411, 96)\n",
            "(699, 96)\n",
            "(1064, 96)\n",
            "(799, 96)\n",
            "(894, 96)\n",
            "(1492, 96)\n",
            "(1409, 96)\n",
            "(1473, 96)\n",
            "(1077, 96)\n",
            "(793, 96)\n",
            "(1310, 96)\n",
            "(461, 96)\n",
            "(1282, 96)\n",
            "(1078, 96)\n",
            "(438, 96)\n",
            "(1272, 96)\n",
            "(1164, 96)\n",
            "(755, 96)\n",
            "(950, 96)\n",
            "(522, 96)\n",
            "(440, 96)\n",
            "(913, 96)\n",
            "(1115, 96)\n",
            "(1159, 96)\n",
            "(1102, 96)\n",
            "(500, 96)\n",
            "(1217, 96)\n",
            "(1105, 96)\n",
            "(483, 96)\n",
            "(1317, 96)\n",
            "(1444, 96)\n",
            "(913, 96)\n",
            "(992, 96)\n",
            "(1481, 96)\n",
            "(1010, 96)\n",
            "(471, 96)\n",
            "(745, 96)\n",
            "(1404, 96)\n",
            "(968, 96)\n",
            "(346, 96)\n",
            "(1034, 96)\n",
            "(1111, 96)\n",
            "(1203, 96)\n",
            "(976, 96)\n",
            "(980, 96)\n",
            "(1131, 96)\n",
            "(1168, 96)\n",
            "(1006, 96)\n",
            "(1075, 96)\n",
            "(1020, 96)\n",
            "(652, 96)\n",
            "(851, 96)\n",
            "(711, 96)\n",
            "(1496, 96)\n",
            "(932, 96)\n",
            "(1158, 96)\n",
            "(1102, 96)\n",
            "(1145, 96)\n",
            "(250, 96)\n",
            "(1216, 96)\n",
            "(929, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwCgThH-AaDL"
      },
      "outputs": [],
      "source": [
        "outputs = outputs.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSyqpayCAQ68"
      },
      "outputs": [],
      "source": [
        "np.save(\"/content/output.npy\", outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykBfv3fBAnU5",
        "outputId": "a12cd248-1d76-4c19-8e77-9b6bdd681bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-e630c79d24bf>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  predicted_ids = torch.argmax(torch.tensor(x), dim=1)\n"
          ]
        }
      ],
      "source": [
        "# /content/drive/MyDrive/output_alignment_fusion/3130303538355f3338.npy\n",
        "!pip install torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "# import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "# import numpy as np\n",
        "# from char_embedding import tensor_to_text\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "\n",
        "x = np.load(\"/content/output.npy\")\n",
        "\n",
        "# print(x)\n",
        "\n",
        "x = torch.tensor(x)\n",
        "predicted_ids = torch.argmax(torch.tensor(x), dim=1)\n",
        "\n",
        "\n",
        "x = torch.log_softmax(x, dim=-1)\n",
        "x = x.cpu().detach()\n",
        "\n",
        "\n",
        "labels = ('ắ', 'ồ', 'z', 'ứ', 'ỡ', 'ì', 'x', 'ặ', 'u', 'ẹ', 'd', 'ỵ', 'r', 'p', 't', 'ỳ', 'ẩ', 'f', 'ó', 'á', 'v', 'ã', 'i', 'ư', 'ở', 'ễ', 'ụ', 'ú', 'ũ', ' ', 'ă', 'é', 'ằ', 'a', 'ấ', 'ờ', 'ữ', 'ớ', 'n', 'ý', 's', 'h', 'ơ', 'ị', 'l', 'c', 'k', 'ỷ', 'ỗ', 'ế', 'ẻ', 'ợ', 'ẫ', 'í', 'ỏ', 'ủ', 'g', 'q', 'j', 'ò', 'ỹ', 'ự', 'ô', 'b', 'y', 'ĩ', 'ỉ', 'ẵ', 'ầ', 'ê', 'ộ', 'ậ', 'm', 'ń', 'o', 'ọ', 'đ', 'ẽ', 'ử', 'à', 'è', 'e', 'ẳ', 'ổ', 'ù', 'w', 'ả', 'ạ', 'â', 'ệ', 'ề', 'õ', 'ố', 'ể', 'ừ',)\n",
        "\n",
        "def clean_corpus(str1):\n",
        "    res1 = \"\"\n",
        "    for i in str1:\n",
        "        if i.isalpha() or i==\" \":\n",
        "            res1 = \"\".join([res1, i])\n",
        "    return res1.lower()\n",
        "transcript = \" \" + 'Trăng cô đơn lặng lẽ Nhớ ai qua từng Góc phố ngày xưa Nghe trong tim vụn vỡ Bao lần nát tan vì ai Có ai nhớ ngày Xưa em ơi Giờ đã xa tôi mất rồi Ánh trăng sáng Lòng anh em ơi Giờ thấm ướt' + \"\"\n",
        "transcript = clean_corpus(transcript)\n",
        "dictionary = {c: i for i, c in enumerate(labels)}\n",
        "\n",
        "tokens = [dictionary[c] for c in transcript]\n",
        "\n",
        "\n",
        "def get_trellis(x, tokens, blank_id=95):\n",
        "    num_frame = x.size(0)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Trellis has extra diemsions for both time axis and tokens.\n",
        "    # The extra dim for tokens represents <SoS> (start-of-sentence)\n",
        "    # The extra dim for time axis is for simplification of the code.\n",
        "    trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
        "    trellis[0, 0] = 0\n",
        "    trellis[1:, 0] = torch.cumsum(x[:, 0], 0)\n",
        "    trellis[0, -num_tokens:] = -float(\"inf\")\n",
        "    trellis[-num_tokens:, 0] = float(\"inf\")\n",
        "\n",
        "    for t in range(num_frame):\n",
        "        trellis[t + 1, 1:] = torch.maximum(\n",
        "            # Score for staying at the same token\n",
        "            trellis[t, 1:] + x[t, blank_id],\n",
        "            # Score for changing to the next token\n",
        "            trellis[t, :-1] + x[t, tokens],\n",
        "        )\n",
        "    return trellis\n",
        "\n",
        "\n",
        "trellis = get_trellis(x, tokens)\n",
        "\n",
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class Point:\n",
        "  token_index: int\n",
        "  time_index: int\n",
        "  score: float\n",
        "\n",
        "\n",
        "def backtrack(trellis, emission, tokens, blank_id=95):\n",
        "  # Note:\n",
        "  # j and t are indices for trellis, which has extra dimensions \n",
        "  # for time and tokens at the beginning.\n",
        "  # When refering to time frame index `T` in trellis,\n",
        "  # the corresponding index in emission is `T-1`.\n",
        "  # Similarly, when refering to token index `J` in trellis,\n",
        "  # the corresponding index in transcript is `J-1`.\n",
        "  j = trellis.size(1) - 1\n",
        "  t_start = torch.argmax(trellis[:, j]).item()\n",
        "\n",
        "  path = []\n",
        "  for t in range(t_start, 0, -1):\n",
        "    # 1. Figure out if the current position was stay or change\n",
        "    # Note (again):\n",
        "    # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n",
        "    # Score for token staying the same from time frame J-1 to T.\n",
        "    stayed = trellis[t-1, j] + emission[t-1, blank_id]\n",
        "    # Score for token changing from C-1 at T-1 to J at T.\n",
        "    changed = trellis[t-1, j-1] + emission[t-1, tokens[j-1]]\n",
        "\n",
        "    # 2. Store the path with frame-wise probability.\n",
        "    prob = emission[t-1, tokens[j-1] if changed > stayed else 0].exp().item()\n",
        "    # Return token index and time index in non-trellis coordinate.\n",
        "    path.append(Point(j-1, t-1, prob))\n",
        "\n",
        "    # 3. Update the token\n",
        "    if changed > stayed:\n",
        "      j -= 1\n",
        "      if j == 0:\n",
        "        break\n",
        "  else:\n",
        "    raise ValueError('Failed to align')\n",
        "  return path[::-1]\n",
        "\n",
        "path = backtrack(trellis, x, tokens)\n",
        "@dataclass\n",
        "class Segment:\n",
        "    label: str\n",
        "    start: int\n",
        "    end: int\n",
        "    score: float\n",
        "    \n",
        "\n",
        "    def __repr__(self):\n",
        "      return f\"{self.start} --> {self.end} {self.label} \\n\"\n",
        "\n",
        "    @property\n",
        "    def length(self):\n",
        "        return self.end - self.start\n",
        "\n",
        "\n",
        "def merge_repeats(path):\n",
        "    i1, i2 = 0, 0\n",
        "    segments = []\n",
        "    while i1 < len(path):\n",
        "        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
        "            i2 += 1\n",
        "        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
        "        segments.append(\n",
        "            Segment(\n",
        "                transcript[path[i1].token_index],\n",
        "                path[i1].time_index,\n",
        "                path[i2 - 1].time_index + 1,\n",
        "                score,\n",
        "            )\n",
        "        )\n",
        "        i1 = i2\n",
        "    return segments\n",
        "\n",
        "\n",
        "segments = merge_repeats(path)\n",
        "\n",
        "# Merge words\n",
        "def merge_words(segments, separator=\" \"):\n",
        "    words = []\n",
        "    i1, i2 = 0, 0\n",
        "    while i1 < len(segments):\n",
        "        if i2 >= len(segments) or segments[i2].label == separator:\n",
        "            if i1 != i2:\n",
        "                segs = segments[i1:i2]\n",
        "                word = \"\".join([seg.label for seg in segs])\n",
        "                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "                words.append(Segment(word, segments[i1].start*20, segments[i2 - 1].end*20, score))\n",
        "            i1 = i2 + 1\n",
        "            i2 = i1\n",
        "        else:\n",
        "            i2 += 1\n",
        "    return words\n",
        "\n",
        "\n",
        "word_segments = merge_words(segments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ONaFso-A7Sd",
        "outputId": "85e1b313-a035-412a-d847-9a292ba2a1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.180000 --> 0.520000 trăng \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(word_segments[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvLb-mptCr2W",
        "outputId": "fdddd747-e785-4283-eda2-f88e06b769ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['180.000000', '-->', '520.000000', 'trăng', '\\n']\n"
          ]
        }
      ],
      "source": [
        "print(str(word_segments[0]).split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-hbfwocC_BH"
      },
      "outputs": [],
      "source": [
        "def format_millis(milliseconds):\n",
        "  millis = milliseconds\n",
        "  millisecond = int(millis%1000)\n",
        "  millisecond = str(millisecond)\n",
        "  if len(millisecond)==0:\n",
        "    millisecond = '000'\n",
        "  elif len(millisecond) == 1:\n",
        "    millisecond = '00' + millisecond\n",
        "  elif len(millisecond) == 2:\n",
        "    millisecond = '0' + millisecond\n",
        "\n",
        "  seconds=(millis/1000)%60\n",
        "  seconds = int(seconds)\n",
        "  seconds = str(seconds)\n",
        "  if len(seconds) == 1:\n",
        "    seconds = '0' + seconds\n",
        "  minutes=(millis/(1000*60))%60\n",
        "  \n",
        "  minutes = int(minutes)\n",
        "  minutes = str(minutes)\n",
        "  if len(minutes) == 1:\n",
        "    minutes = '0' + minutes\n",
        "\n",
        "  hours=(millis/(1000*60*60))%24\n",
        "  hours = int(hours)\n",
        "  hours = str(hours)\n",
        "  if len(hours) == 1:\n",
        "    hours = '0' + hours\n",
        "\n",
        "  return (hours + \":\" + minutes + \":\" +  seconds + \",\" + millisecond)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdgqMQLqRKL3",
        "outputId": "032cf633-2818-4283-8785-0a184db4cb83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00:00:06,240\n"
          ]
        }
      ],
      "source": [
        "print(format_millis(6240))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rogket9PES8W",
        "outputId": "2c3f30b6-2bd4-4ddd-f0ea-bd0d54a947a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:0:2,500\n"
          ]
        }
      ],
      "source": [
        "f = open(\"/content/output.srt\", \"a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp5tEDqhCTd_",
        "outputId": "838120ec-e5ed-4588-e8fa-f11289a2f586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:0:0,180\n",
            "0:0:0,520\n",
            "trăng\n",
            "0:0:0,540\n",
            "0:0:0,700\n",
            "cô\n",
            "0:0:0,840\n",
            "0:0:1,40\n",
            "đơn\n",
            "0:0:1,160\n",
            "0:0:1,340\n",
            "lặng\n",
            "0:0:1,460\n",
            "0:0:1,640\n",
            "lẽ\n",
            "0:0:1,800\n",
            "0:0:2,80\n",
            "nhớ\n",
            "0:0:2,200\n",
            "0:0:2,280\n",
            "ai\n",
            "0:0:2,400\n",
            "0:0:2,580\n",
            "qua\n",
            "0:0:2,720\n",
            "0:0:2,980\n",
            "từng\n",
            "0:0:3,40\n",
            "0:0:3,180\n",
            "góc\n",
            "0:0:3,340\n",
            "0:0:3,620\n",
            "phố\n",
            "0:0:3,680\n",
            "0:0:3,880\n",
            "ngày\n",
            "0:0:4,120\n",
            "0:0:5,60\n",
            "xưa\n",
            "0:0:5,220\n",
            "0:0:5,420\n",
            "nghe\n",
            "0:0:5,540\n",
            "0:0:5,720\n",
            "trong\n",
            "0:0:5,880\n",
            "0:0:6,140\n",
            "tim\n",
            "0:0:6,200\n",
            "0:0:6,440\n",
            "vụn\n",
            "0:0:6,500\n",
            "0:0:6,900\n",
            "vỡ\n",
            "0:0:6,980\n",
            "0:0:7,340\n",
            "bao\n",
            "0:0:7,440\n",
            "0:0:7,680\n",
            "lần\n",
            "0:0:7,740\n",
            "0:0:7,960\n",
            "nát\n",
            "0:0:8,80\n",
            "0:0:8,620\n",
            "tan\n",
            "0:0:8,720\n",
            "0:0:9,0\n",
            "vì\n",
            "0:0:9,180\n",
            "0:0:10,220\n",
            "ai\n",
            "0:0:10,300\n",
            "0:0:10,480\n",
            "có\n",
            "0:0:10,740\n",
            "0:0:10,840\n",
            "ai\n",
            "0:0:10,960\n",
            "0:0:11,140\n",
            "nhớ\n",
            "0:0:11,220\n",
            "0:0:11,380\n",
            "ngày\n",
            "0:0:11,520\n",
            "0:0:11,720\n",
            "xưa\n",
            "0:0:11,840\n",
            "0:0:11,960\n",
            "em\n",
            "0:0:12,160\n",
            "0:0:12,580\n",
            "ơi\n",
            "0:0:12,660\n",
            "0:0:12,820\n",
            "giờ\n",
            "0:0:12,840\n",
            "0:0:13,20\n",
            "đã\n",
            "0:0:13,120\n",
            "0:0:13,280\n",
            "xa\n",
            "0:0:13,360\n",
            "0:0:13,580\n",
            "tôi\n",
            "0:0:13,640\n",
            "0:0:13,800\n",
            "mất\n",
            "0:0:14,0\n",
            "0:0:15,220\n",
            "rồi\n",
            "0:0:15,420\n",
            "0:0:15,500\n",
            "ánh\n",
            "0:0:15,580\n",
            "0:0:15,720\n",
            "trăng\n",
            "0:0:15,860\n",
            "0:0:16,80\n",
            "sáng\n",
            "0:0:16,260\n",
            "0:0:16,520\n",
            "lòng\n",
            "0:0:16,660\n",
            "0:0:16,720\n",
            "anh\n",
            "0:0:16,920\n",
            "0:0:17,20\n",
            "em\n",
            "0:0:17,220\n",
            "0:0:17,280\n",
            "ơi\n",
            "0:0:17,520\n",
            "0:0:17,680\n",
            "giờ\n",
            "0:0:17,840\n",
            "0:0:18,20\n",
            "thấm\n",
            "0:0:18,140\n",
            "0:0:18,200\n",
            "ướt\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(word_segments)):\n",
        "  word_segments[i] = str(word_segments[i])\n",
        "  start = word_segments[i].split(\" \")[0]\n",
        "  end = word_segments[i].split(\" \")[2]\n",
        "  word = word_segments[i].split(\" \")[3]\n",
        "\n",
        "  f.write(str(i+1) + \"\\n\" + str(format_millis(int(start))) + \" --> \" + str(format_millis(int(end))) + \"\\n\" + str(word) + \"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1VJ3gRlU0tt",
        "outputId": "71ac30ab-7590-4523-bf2c-c132335ab294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "import unidecode\n",
        " \n",
        "def remove_accent(text):\n",
        "    return unidecode.unidecode(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rao6eE7nOoLh",
        "outputId": "b77bb707-55f5-4215-a90b-1b6613b026c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
            "\u001b[0mInput #0, wav, from '/content/37303234365f3231.wav':\n",
            "  Duration: 00:00:18.29, bitrate: 1411 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e540] \u001b[0mShaper: FriBidi 0.19.7 (SIMPLE) HarfBuzz-ng 2.6.4 (COMPLEX)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e540] \u001b[0mUsing font provider fontconfig\n",
            "File 'output.mp4' already exists. Overwrite ? [y/N] y\n",
            "Stream mapping:\n",
            "  subtitles (graph 0) -> Stream #0:0 (libx264)\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mShaper: FriBidi 0.19.7 (SIMPLE) HarfBuzz-ng 2.6.4 (COMPLEX)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mUsing font provider fontconfig\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mprofile High, level 1.3\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'output.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 320x240 [SAR 1:1 DAR 4:3], q=-1--1, 25 fps, 12800 tbn, 25 tbc (default)\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 aac\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mfontselect: (Arial, 400, 0) -> /usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf, 0, LiberationSans\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EB7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EBD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EEB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EEB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EEB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EEB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EEB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EEB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EEB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EEB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EE1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA7 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1ED3 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1A1 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDD not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EA5 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1B0 not found, selecting one more font for (Arial, 400, 0)\n",
            "\u001b[1;32m[Parsed_subtitles_1 @ 0x55d94bf4e6c0] \u001b[0mGlyph 0x1EDB not found, selecting one more font for (Arial, 400, 0)\n",
            "frame=  506 fps=0.0 q=-1.0 Lsize=     320kB time=00:00:20.12 bitrate= 130.3kbits/s speed=26.1x    \n",
            "video:16kB audio:287kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 5.590338%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mframe I:3     Avg QP: 7.26  size:    64\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mframe P:126   Avg QP:11.00  size:    64\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mframe B:377   Avg QP:12.70  size:    19\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mconsecutive B-frames:  0.6%  0.0%  0.6% 98.8%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mmb I  I16..4: 100.0%  0.0%  0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mmb P  I16..4:  0.2%  0.0%  0.2%  P16..4:  0.1%  0.1%  0.0%  0.0%  0.0%    skip:99.4%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.7%  0.0%  0.0%  direct: 0.0%  skip:99.3%  L0:51.4% L1:48.6% BI: 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0m8x8 transform intra:0.9% inter:2.2%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mcoded y,uvDC,uvAC intra: 3.3% 0.0% 0.0% inter: 0.0% 0.0% 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mi16 v,h,dc,p: 94%  0%  6%  0%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  2% 28% 50%  8%  8%  2%  2%  0%  0%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 18% 17% 56%  1%  1%  2%  2%  2%  2%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mi8c dc,h,v,p: 100%  0%  0%  0%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mWeighted P-Frames: Y:2.4% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mref P L0: 60.6%  2.5% 28.8%  7.5%  0.6%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mref B L0: 75.4% 23.2%  1.5%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mref B L1: 99.5%  0.5%\n",
            "\u001b[1;36m[libx264 @ 0x55d94bf8ba80] \u001b[0mkb/s:6.13\n",
            "\u001b[1;36m[aac @ 0x55d94bf8ad00] \u001b[0mQavg: 180.753\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -i /content/37303234365f3231.wav -filter_complex \"color=c=black,subtitles=/content/output.txt[v]\" -map \"[v]\" -map 0:a -c:a aac -shortest output.mp4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}