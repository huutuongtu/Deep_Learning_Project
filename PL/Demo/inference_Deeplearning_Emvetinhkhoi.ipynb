{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0BZ-2Ck9iI6",
        "outputId": "fe06f16c-a44c-4cdf-a66c-6088c36f8551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install cmath\n",
        "!pip install torch\n",
        "!pip install sklearn\n",
        "!pip install pandas\n",
        "!pip install librosa\n",
        "!pip install numpy\n",
        "!pip install speechpy\n",
        "!pip install transformers\n",
        "!pip install jiwer\n",
        "!pip install pyctcdecode\n",
        "\n",
        "from pyctcdecode import build_ctcdecoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8w-q5Bm-Et1",
        "outputId": "ba711c14-6804-4a49-eebe-1560acba5e8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0.post1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.25.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: speechpy in /usr/local/lib/python3.8/dist-packages (2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.8/dist-packages (2.5.1)\n",
            "Requirement already satisfied: levenshtein==0.20.2 in /usr/local/lib/python3.8/dist-packages (from jiwer) (0.20.2)\n",
            "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from levenshtein==0.20.2->jiwer) (2.13.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyctcdecode in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: hypothesis<7,>=6.14 in /usr/local/lib/python3.8/dist-packages (from pyctcdecode) (6.64.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from pyctcdecode) (1.21.6)\n",
            "Requirement already satisfied: pygtrie<3.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from pyctcdecode) (2.5.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (1.1.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (22.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyctcdecode.language_model:kenlm python bindings are not installed. Most likely you want to install it using: pip install https://github.com/kpu/kenlm/archive/master.zip\n",
            "WARNING:pyctcdecode.decoder:kenlm python bindings are not installed. Most likely you want to install it using: pip install https://github.com/kpu/kenlm/archive/master.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "!pip install pydub\n",
        "!pip install moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlRE7ILDL8OJ",
        "outputId": "b6d932d3-dbf1-4f4d-a057-fc17f73d77a0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.8/dist-packages (12.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio-ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUFDbVyTMI2L",
        "outputId": "ea7b364b-5a3d-41df-f095-a60a664ce7af"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.8/dist-packages (0.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35HaP_rI-CJ8",
        "outputId": "af6f76d8-cf8f-4063-974f-6cc5d0fc81a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from model import Net\n",
        "# from cProfile import label\n",
        "# from infer import phonetic_embedding\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from phonetic_encoder import Phonetic_encoder\n",
        "from acoustic_encoder import Acoustic_encoder\n",
        "from linguistic_encoder import Linguistic_encoder\n",
        "from char_embedding import text_to_tensor, clean_corpus\n",
        "from help import wav_norm, Atention\n",
        "import numpy as np\n",
        "# from help import beam_search_decoding\n",
        "from model import Acoustic_Phonetic_Linguistic\n",
        "# from dataloader import MDD_Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from jiwer import wer, cer\n",
        "tokenizer = Wav2Vec2Processor.from_pretrained(\"pretrained_finetuned\")\n",
        "\n",
        "net = Acoustic_Phonetic_Linguistic()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu_pd_h7-JfP",
        "outputId": "d028a88b-9ec8-4b8a-fab8-5f2b84eb1b2a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPznFy-VPVMc",
        "outputId": "89fad41b-ab00-4944-c4ba-eb653bad92a9"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import numpy\n",
        "from pytube import YouTube, Playlist\n",
        "import pytube\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import subprocess\n",
        "\n",
        "\n",
        "# from moviepy.editor import *\n",
        "import glob\n",
        "from pydub import AudioSegment\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "#download setting\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# video index to continue crawling, index = 0 means the first video\n",
        "START_INDEX = 0\n",
        "\n",
        "# importing the module\n",
        "from pytube import YouTube\n",
        "\n",
        "from pytube import YouTube\n",
        "yt = YouTube('https://www.youtube.com/watch?v=GuiuiVnh6WM&ab_channel=T%E1%BA%A1QuangTh%E1%BA%AFng')\n",
        "yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution')[-1].download()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KAQIzFq6K4LD",
        "outputId": "c7ff0882-0954-416a-94ab-1b586946bc25"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Em về tinh khôi - Tạ Quang Thắng.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"ffmpeg -i test.mp4 -ab 160k -ac 2 -ar 44100 -vn /content/test.wav\"\n",
        "subprocess.call(command, shell=True)\n",
        "\n",
        "i = 'test.wav'\n",
        "y, sr = torchaudio.load(i)       \n",
        "y_16k = F.resample(y, sr, 16000)\n",
        "y_16k = y_16k.numpy()\n",
        "y_mono = librosa.to_mono(y_16k)\n",
        "sf.write(i, y_mono, 16000)"
      ],
      "metadata": {
        "id": "lt4O7n3zPvzc"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "t1 = 30 * 1000 #Works in milliseconds\n",
        "t2 = 48 * 1000\n",
        "newAudio = AudioSegment.from_wav(\"test.wav\")\n",
        "newAudio = newAudio[t1:t2]\n",
        "newAudio.export('test.wav', format=\"wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dopqb4I7P-Z8",
        "outputId": "ff39fa99-2703-41b4-8c7e-8c9079ea59f5"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='test.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6PyFHvQqM-",
        "outputId": "e37b521d-2149-4893-b401-e95fce921816"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1ncKv8HTuRf",
        "outputId": "3d75eb0a-6afd-4062-9a37-42da5edbc8d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from infer import phonetic_embedding\n",
        "\n",
        "net = torch.load('/content/drive/MyDrive/PL/MDD_Checkpoint/song_checkpoint.pth')\n",
        "net.eval().to('cuda')\n",
        "path = '/content/test.wav'\n",
        "lyrics = 'Bờ vai ơi đừng quá nghiêng nghiêng Đánh rơi buổi chiều thơm ngát Làn môi ơi đừng quá run run Lỡ tia nắng hồng tan mất Xin'\n",
        "phonetic = phonetic_embedding(path).squeeze(0)\n",
        "linguistic = text_to_tensor(lyrics)\n",
        "linguistic = torch.tensor(linguistic)\n",
        "phonetic = phonetic.to('cuda')\n",
        "linguistic = linguistic.to('cuda')\n",
        "phonetic = phonetic.unsqueeze(0)\n",
        "linguistic = linguistic.unsqueeze(0)\n",
        "outputs = net(phonetic, linguistic)\n",
        "outputs = outputs.detach().cpu().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM34oXF2-YWc",
        "outputId": "b1014160-b9ed-44c1-9a6b-0bebb8edfd89"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/PL/linguistic_encoder.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, dtype=torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/output.npy\", outputs)"
      ],
      "metadata": {
        "id": "8vc49LTQ-rEm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/output_alignment_fusion/3130303538355f3338.npy\n",
        "# !pip install torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "# import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "# import numpy as np\n",
        "# from char_embedding import tensor_to_text\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "\n",
        "x = np.load(\"/content/output.npy\")\n",
        "\n",
        "# print(x)\n",
        "\n",
        "x = torch.tensor(x)\n",
        "predicted_ids = torch.argmax(torch.tensor(x), dim=1)\n",
        "\n",
        "\n",
        "x = torch.log_softmax(x, dim=-1)\n",
        "x = x.cpu().detach()\n",
        "\n",
        "\n",
        "labels = ('ắ', 'ồ', 'z', 'ứ', 'ỡ', 'ì', 'x', 'ặ', 'u', 'ẹ', 'd', 'ỵ', 'r', 'p', 't', 'ỳ', 'ẩ', 'f', 'ó', 'á', 'v', 'ã', 'i', 'ư', 'ở', 'ễ', 'ụ', 'ú', 'ũ', ' ', 'ă', 'é', 'ằ', 'a', 'ấ', 'ờ', 'ữ', 'ớ', 'n', 'ý', 's', 'h', 'ơ', 'ị', 'l', 'c', 'k', 'ỷ', 'ỗ', 'ế', 'ẻ', 'ợ', 'ẫ', 'í', 'ỏ', 'ủ', 'g', 'q', 'j', 'ò', 'ỹ', 'ự', 'ô', 'b', 'y', 'ĩ', 'ỉ', 'ẵ', 'ầ', 'ê', 'ộ', 'ậ', 'm', 'ń', 'o', 'ọ', 'đ', 'ẽ', 'ử', 'à', 'è', 'e', 'ẳ', 'ổ', 'ù', 'w', 'ả', 'ạ', 'â', 'ệ', 'ề', 'õ', 'ố', 'ể', 'ừ',)\n",
        "\n",
        "def clean_corpus(str1):\n",
        "    res1 = \"\"\n",
        "    for i in str1:\n",
        "        if i.isalpha() or i==\" \":\n",
        "            res1 = \"\".join([res1, i])\n",
        "    return res1.lower()\n",
        "transcript = \" \" + 'Bờ vai ơi đừng quá nghiêng nghiêng Đánh rơi buổi chiều thơm ngát Làn môi ơi đừng quá run run Lỡ tia nắng hồng tan mất Xin' + \"\"\n",
        "transcript = clean_corpus(transcript)\n",
        "dictionary = {c: i for i, c in enumerate(labels)}\n",
        "\n",
        "tokens = [dictionary[c] for c in transcript]\n",
        "\n",
        "\n",
        "def get_trellis(x, tokens, blank_id=95):\n",
        "    num_frame = x.size(0)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Trellis has extra diemsions for both time axis and tokens.\n",
        "    # The extra dim for tokens represents <SoS> (start-of-sentence)\n",
        "    # The extra dim for time axis is for simplification of the code.\n",
        "    trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
        "    trellis[0, 0] = 0\n",
        "    trellis[1:, 0] = torch.cumsum(x[:, 0], 0)\n",
        "    trellis[0, -num_tokens:] = -float(\"inf\")\n",
        "    trellis[-num_tokens:, 0] = float(\"inf\")\n",
        "\n",
        "    for t in range(num_frame):\n",
        "        trellis[t + 1, 1:] = torch.maximum(\n",
        "            # Score for staying at the same token\n",
        "            trellis[t, 1:] + x[t, blank_id],\n",
        "            # Score for changing to the next token\n",
        "            trellis[t, :-1] + x[t, tokens],\n",
        "        )\n",
        "    return trellis\n",
        "\n",
        "\n",
        "trellis = get_trellis(x, tokens)\n",
        "\n",
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class Point:\n",
        "  token_index: int\n",
        "  time_index: int\n",
        "  score: float\n",
        "\n",
        "\n",
        "def backtrack(trellis, emission, tokens, blank_id=95):\n",
        "  # Note:\n",
        "  # j and t are indices for trellis, which has extra dimensions \n",
        "  # for time and tokens at the beginning.\n",
        "  # When refering to time frame index `T` in trellis,\n",
        "  # the corresponding index in emission is `T-1`.\n",
        "  # Similarly, when refering to token index `J` in trellis,\n",
        "  # the corresponding index in transcript is `J-1`.\n",
        "  j = trellis.size(1) - 1\n",
        "  t_start = torch.argmax(trellis[:, j]).item()\n",
        "\n",
        "  path = []\n",
        "  for t in range(t_start, 0, -1):\n",
        "    # 1. Figure out if the current position was stay or change\n",
        "    # Note (again):\n",
        "    # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n",
        "    # Score for token staying the same from time frame J-1 to T.\n",
        "    stayed = trellis[t-1, j] + emission[t-1, blank_id]\n",
        "    # Score for token changing from C-1 at T-1 to J at T.\n",
        "    changed = trellis[t-1, j-1] + emission[t-1, tokens[j-1]]\n",
        "\n",
        "    # 2. Store the path with frame-wise probability.\n",
        "    prob = emission[t-1, tokens[j-1] if changed > stayed else 0].exp().item()\n",
        "    # Return token index and time index in non-trellis coordinate.\n",
        "    path.append(Point(j-1, t-1, prob))\n",
        "\n",
        "    # 3. Update the token\n",
        "    if changed > stayed:\n",
        "      j -= 1\n",
        "      if j == 0:\n",
        "        break\n",
        "  else:\n",
        "    raise ValueError('Failed to align')\n",
        "  return path[::-1]\n",
        "\n",
        "path = backtrack(trellis, x, tokens)\n",
        "@dataclass\n",
        "class Segment:\n",
        "    label: str\n",
        "    start: int\n",
        "    end: int\n",
        "    score: float\n",
        "    \n",
        "\n",
        "    def __repr__(self):\n",
        "      return f\"{self.start} --> {self.end} {self.label} \\n\"\n",
        "\n",
        "    @property\n",
        "    def length(self):\n",
        "        return self.end - self.start\n",
        "\n",
        "\n",
        "def merge_repeats(path):\n",
        "    i1, i2 = 0, 0\n",
        "    segments = []\n",
        "    while i1 < len(path):\n",
        "        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
        "            i2 += 1\n",
        "        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
        "        segments.append(\n",
        "            Segment(\n",
        "                transcript[path[i1].token_index],\n",
        "                path[i1].time_index,\n",
        "                path[i2 - 1].time_index + 1,\n",
        "                score,\n",
        "            )\n",
        "        )\n",
        "        i1 = i2\n",
        "    return segments\n",
        "\n",
        "\n",
        "segments = merge_repeats(path)\n",
        "\n",
        "# Merge words\n",
        "def merge_words(segments, separator=\" \"):\n",
        "    words = []\n",
        "    i1, i2 = 0, 0\n",
        "    while i1 < len(segments):\n",
        "        if i2 >= len(segments) or segments[i2].label == separator:\n",
        "            if i1 != i2:\n",
        "                segs = segments[i1:i2]\n",
        "                word = \"\".join([seg.label for seg in segs])\n",
        "                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "                words.append(Segment(word, segments[i1].start*20, segments[i2 - 1].end*20, score))\n",
        "            i1 = i2 + 1\n",
        "            i2 = i1\n",
        "        else:\n",
        "            i2 += 1\n",
        "    return words\n",
        "\n",
        "\n",
        "word_segments = merge_words(segments)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcI7rHUh_Bbz",
        "outputId": "f3c64dc9-f125-4f95-93af-5dd69b8aedcf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-a7cdf88bd7e4>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  predicted_ids = torch.argmax(torch.tensor(x), dim=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_millis(milliseconds):\n",
        "  millis = milliseconds\n",
        "  millisecond = int(millis%1000)\n",
        "  millisecond = str(millisecond)\n",
        "  if len(millisecond)==0:\n",
        "    millisecond = '000'\n",
        "  elif len(millisecond) == 1:\n",
        "    millisecond = '00' + millisecond\n",
        "  elif len(millisecond) == 2:\n",
        "    millisecond = '0' + millisecond\n",
        "\n",
        "  seconds=(millis/1000)%60\n",
        "  seconds = int(seconds)\n",
        "  seconds = str(seconds)\n",
        "  if len(seconds) == 1:\n",
        "    seconds = '0' + seconds\n",
        "  minutes=(millis/(1000*60))%60\n",
        "  \n",
        "  minutes = int(minutes)\n",
        "  minutes = str(minutes)\n",
        "  if len(minutes) == 1:\n",
        "    minutes = '0' + minutes\n",
        "\n",
        "  hours=(millis/(1000*60*60))%24\n",
        "  hours = int(hours)\n",
        "  hours = str(hours)\n",
        "  if len(hours) == 1:\n",
        "    hours = '0' + hours\n",
        "\n",
        "  return (hours + \":\" + minutes + \":\" +  seconds + \",\" + millisecond)"
      ],
      "metadata": {
        "id": "u5EQ36cu_Dat"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/emvetinhkhoi.srt\", \"a\")\n",
        "for i in range(len(word_segments)):\n",
        " \n",
        "  if (i==0):\n",
        "    start = str(str(word_segments[i])).split(\" \")[0]\n",
        "    end_before = int(str(str(word_segments[i])).split(\" \")[2])\n",
        "    word = str(str(word_segments[i])).split(\" \")[3]\n",
        "    if int(start)>=200:\n",
        "      start = int(start)-200\n",
        "    else:\n",
        "      start = 0\n",
        "    start_next = int(str(word_segments[i+1]).split(\" \")[0])\n",
        "    end = (2*end_before + start_next)/3\n",
        "  elif i==len(word_segments)-1:\n",
        "    end_before = int(str(word_segments[i-1]).split(\" \")[2])\n",
        "    start_next = int(str(word_segments[i]).split(\" \")[0])\n",
        "    end = int(str(word_segments[i]).split(\" \")[2]) + 250\n",
        "    start = (2*end_before+start_next)/3\n",
        "    word = str(word_segments[i]).split(\" \")[3]\n",
        "  else:\n",
        "    end_before = int(str(word_segments[i-1]).split(\" \")[2])\n",
        "    start_next = int(str(word_segments[i+1]).split(\" \")[0])\n",
        "    end = int(str(word_segments[i]).split(\" \")[2])\n",
        "    start = int(str(word_segments[i]).split(\" \")[0])\n",
        "    start = (2*end_before+start)/3\n",
        "    end = (2*end + start_next)/3\n",
        "    word = str(word_segments[i]).split(\" \")[3]\n",
        "  \n",
        "  start = (format_millis(start))\n",
        "  end = (format_millis(end))\n",
        "  one_line = str(i+1) + \"\\n\" + start + \" --> \" + end + \"\\n\" + str(word) + \"\\n\\n\"\n",
        "  print(one_line)\n",
        "  f.write(one_line)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaCYVgqQ_Ggq",
        "outputId": "bcf81124-e355-48b4-d6b9-1a2b4d6cb40a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "00:00:02,060 --> 00:00:02,473\n",
            "bờ\n",
            "\n",
            "\n",
            "2\n",
            "00:00:02,473 --> 00:00:02,800\n",
            "vai\n",
            "\n",
            "\n",
            "3\n",
            "00:00:02,800 --> 00:00:03,093\n",
            "ơi\n",
            "\n",
            "\n",
            "4\n",
            "00:00:03,093 --> 00:00:03,440\n",
            "đừng\n",
            "\n",
            "\n",
            "5\n",
            "00:00:03,440 --> 00:00:04,133\n",
            "quá\n",
            "\n",
            "\n",
            "6\n",
            "00:00:04,133 --> 00:00:04,426\n",
            "nghiêng\n",
            "\n",
            "\n",
            "7\n",
            "00:00:04,426 --> 00:00:05,633\n",
            "nghiêng\n",
            "\n",
            "\n",
            "8\n",
            "00:00:05,633 --> 00:00:05,926\n",
            "đánh\n",
            "\n",
            "\n",
            "9\n",
            "00:00:05,926 --> 00:00:06,286\n",
            "rơi\n",
            "\n",
            "\n",
            "10\n",
            "00:00:06,286 --> 00:00:06,626\n",
            "buổi\n",
            "\n",
            "\n",
            "11\n",
            "00:00:06,626 --> 00:00:07,020\n",
            "chiều\n",
            "\n",
            "\n",
            "12\n",
            "00:00:07,020 --> 00:00:07,366\n",
            "thơm\n",
            "\n",
            "\n",
            "13\n",
            "00:00:07,366 --> 00:00:09,926\n",
            "ngát\n",
            "\n",
            "\n",
            "14\n",
            "00:00:09,926 --> 00:00:10,220\n",
            "làn\n",
            "\n",
            "\n",
            "15\n",
            "00:00:10,220 --> 00:00:10,493\n",
            "môi\n",
            "\n",
            "\n",
            "16\n",
            "00:00:10,493 --> 00:00:10,786\n",
            "ơi\n",
            "\n",
            "\n",
            "17\n",
            "00:00:10,786 --> 00:00:11,180\n",
            "đừng\n",
            "\n",
            "\n",
            "18\n",
            "00:00:11,180 --> 00:00:11,953\n",
            "quá\n",
            "\n",
            "\n",
            "19\n",
            "00:00:11,953 --> 00:00:12,200\n",
            "run\n",
            "\n",
            "\n",
            "20\n",
            "00:00:12,200 --> 00:00:13,320\n",
            "run\n",
            "\n",
            "\n",
            "21\n",
            "00:00:13,320 --> 00:00:13,646\n",
            "lỡ\n",
            "\n",
            "\n",
            "22\n",
            "00:00:13,646 --> 00:00:14,013\n",
            "tia\n",
            "\n",
            "\n",
            "23\n",
            "00:00:14,013 --> 00:00:14,353\n",
            "nắng\n",
            "\n",
            "\n",
            "24\n",
            "00:00:14,353 --> 00:00:14,733\n",
            "hồng\n",
            "\n",
            "\n",
            "25\n",
            "00:00:14,733 --> 00:00:15,100\n",
            "tan\n",
            "\n",
            "\n",
            "26\n",
            "00:00:15,100 --> 00:00:17,273\n",
            "mất\n",
            "\n",
            "\n",
            "27\n",
            "00:00:17,273 --> 00:00:18,150\n",
            "xin\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i /content/lyric_align.jpg -i \"/content/test.wav\" -sub_charenc utf-8 -i \"/content/emvetinhkhoi.srt\" \"/content/OUTPUT.mp4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPQuNbKWD9Om",
        "outputId": "17452060-3b42-4518-c9fc-cd0e3fbe2cd4"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, image2, from '/content/lyric_align.jpg':\n",
            "  Duration: 00:00:00.04, start: 0.000000, bitrate: 5082 kb/s\n",
            "    Stream #0:0: Video: mjpeg (Progressive), yuvj444p(pc, bt470bg/unknown/unknown), 612x357 [SAR 300:300 DAR 12:7], 25 tbr, 25 tbn, 25 tbc\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : mono\n",
            "\u001b[0mInput #1, wav, from '/content/test.wav':\n",
            "  Duration: 00:00:18.00, bitrate: 256 kb/s\n",
            "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "Input #2, srt, from '/content/emvetinhkhoi.srt':\n",
            "  Duration: N/A, bitrate: N/A\n",
            "    Stream #2:0: Subtitle: subrip\n",
            "File '/content/OUTPUT.mp4' already exists. Overwrite ? [y/N] ^C\n"
          ]
        }
      ]
    }
  ]
}