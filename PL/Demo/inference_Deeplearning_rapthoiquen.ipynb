{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0BZ-2Ck9iI6",
        "outputId": "756c15da-e96d-42c8-c28d-33103f56bc52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install cmath\n",
        "!pip install torch\n",
        "!pip install sklearn\n",
        "!pip install pandas\n",
        "!pip install librosa\n",
        "!pip install numpy\n",
        "!pip install speechpy\n",
        "!pip install transformers\n",
        "!pip install jiwer\n",
        "!pip install pyctcdecode\n",
        "\n",
        "from pyctcdecode import build_ctcdecoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8w-q5Bm-Et1",
        "outputId": "501a3bae-f1af-44c3-b9d8-191b7a113981"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=fb8a99d75da85bb6550301b63693c9c0868b99d2e9ad65b55f3b8cd19337d8c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.25.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechpy\n",
            "  Downloading speechpy-2.4-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.21.6)\n",
            "Installing collected packages: speechpy\n",
            "Successfully installed speechpy-2.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein, jiwer\n",
            "Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyctcdecode\n",
            "  Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting hypothesis<7,>=6.14\n",
            "  Downloading hypothesis-6.65.0-py3-none-any.whl (402 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.2/402.2 KB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from pyctcdecode) (1.21.6)\n",
            "Collecting pygtrie<3.0,>=2.1\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Collecting exceptiongroup>=1.0.0\n",
            "  Downloading exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (22.2.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n",
            "Installing collected packages: pygtrie, exceptiongroup, hypothesis, pyctcdecode\n",
            "Successfully installed exceptiongroup-1.1.0 hypothesis-6.65.0 pyctcdecode-0.5.0 pygtrie-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyctcdecode.language_model:kenlm python bindings are not installed. Most likely you want to install it using: pip install https://github.com/kpu/kenlm/archive/master.zip\n",
            "WARNING:pyctcdecode.decoder:kenlm python bindings are not installed. Most likely you want to install it using: pip install https://github.com/kpu/kenlm/archive/master.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube\n",
        "!pip install pydub\n",
        "!pip install moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlRE7ILDL8OJ",
        "outputId": "fc012bbe-aad5-4adb-e687-45f6f3e5a70b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio-ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUFDbVyTMI2L",
        "outputId": "e9b243c5-3665-4ce5-9ac1-ca444f17a70b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35HaP_rI-CJ8",
        "outputId": "fdaafb8e-6f4a-44cd-a0c8-af21db4a0ecc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from model import Net\n",
        "# from cProfile import label\n",
        "# from infer import phonetic_embedding\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from phonetic_encoder import Phonetic_encoder\n",
        "from acoustic_encoder import Acoustic_encoder\n",
        "from linguistic_encoder import Linguistic_encoder\n",
        "from char_embedding import text_to_tensor, clean_corpus\n",
        "from help import wav_norm, Atention\n",
        "import numpy as np\n",
        "# from help import beam_search_decoding\n",
        "from model import Acoustic_Phonetic_Linguistic\n",
        "# from dataloader import MDD_Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from jiwer import wer, cer\n",
        "tokenizer = Wav2Vec2Processor.from_pretrained(\"pretrained_finetuned\")\n",
        "\n",
        "net = Acoustic_Phonetic_Linguistic()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu_pd_h7-JfP",
        "outputId": "354b405b-4130-458e-93e4-30b7ed796a29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py:375: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPznFy-VPVMc",
        "outputId": "77e5e652-1db2-4f9c-d3cf-ffe70bc49033"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import numpy\n",
        "from pytube import YouTube, Playlist\n",
        "import pytube\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import subprocess\n",
        "\n",
        "\n",
        "# from moviepy.editor import *\n",
        "import glob\n",
        "from pydub import AudioSegment\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "#download setting\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# video index to continue crawling, index = 0 means the first video\n",
        "START_INDEX = 0\n",
        "\n",
        "# importing the module\n",
        "from pytube import YouTube\n",
        "\n",
        "from pytube import YouTube\n",
        "yt = YouTube('https://www.youtube.com/watch?v=spdAiWwkBtE&ab_channel=AnhChillOfficial')\n",
        "yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution')[-1].download()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KAQIzFq6K4LD",
        "outputId": "d657b4a3-6b3d-48bf-fec5-8b5553bf000b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Thói Quen-Hoàng Dũng-GDucky Rap Cover.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = glob.glob(\"*.mp4\")\n",
        "for i in range(len(x)):\n",
        "  os.rename(x[0], 'test.mp4')"
      ],
      "metadata": {
        "id": "CYWVuicSk8yI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"ffmpeg -i test.mp4 -ab 160k -ac 2 -ar 44100 -vn /content/test.wav\"\n",
        "subprocess.call(command, shell=True)\n",
        "\n",
        "i = 'test.wav'\n",
        "y, sr = torchaudio.load(i)       \n",
        "y_16k = F.resample(y, sr, 16000)\n",
        "y_16k = y_16k.numpy()\n",
        "y_mono = librosa.to_mono(y_16k)\n",
        "sf.write(i, y_mono, 16000)"
      ],
      "metadata": {
        "id": "lt4O7n3zPvzc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pydub import AudioSegment\n",
        "# t1 = 26 * 1000 #Works in milliseconds\n",
        "# t2 = 56 * 1000\n",
        "# newAudio = AudioSegment.from_wav(\"test.wav\")\n",
        "# newAudio = newAudio[t1:t2]\n",
        "# newAudio.export('test.wav', format=\"wav\")"
      ],
      "metadata": {
        "id": "Dopqb4I7P-Z8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6PyFHvQqM-",
        "outputId": "8ea2ca86-00c9-4759-e30b-a994f1c3f7a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from infer import phonetic_embedding\n",
        "\n",
        "net = torch.load('/content/drive/MyDrive/PL/MDD_Checkpoint/song_checkpoint.pth')\n",
        "net.eval().to('cuda')\n",
        "path = '/content/test.wav'\n",
        "lyrics = 'Nửa năm từ khi em ra đi, anh chẳng khác là bao Thuốc thì không hút mấy, nhưng một khi đã hút là nát cả bao Bạn anh hỏi giải pháp là sao? Dạo này không thấy khát và khao? Anh trả lời dạo này chỉ muốn căn nhà 2 đứa có rap và tao ? Mà thôi ông ơi Về Bia rượu thì là tôi không chơi Cố nhắm mắt để ngủ sớm, sáng mai đi tập và sau đó thì là bơi, xông hơi Yeah im feeling so gud Trưa ăn cơm, ban đêm anh ăn soup Làm việc hàng ngày nhưng mà lười một chút Thiền định là vào tầm là mười một phút yeah yeah But u killin me god Yeah yeah Không còn em kế bên Tôi đang làm quen được bao điều hay nhưng sao tôi không thể quên But u killin me god Yeah yeah Không còn em kế bên Tôi đang làm quen được bao điều hay nhưng sao tôi không thể quên Làm sao quến bao đêm xem phim mì gói em nấu I’m fuckin fall in love. Dù cho nó là một thói quen xấu Sau bao nhiêu đêm tôi đã thao thức, vì còn một điều này cần phải giấu I still keep it rollin roll buông ra câu i love u so'\n",
        "phonetic = phonetic_embedding(path).squeeze(0)\n",
        "linguistic = text_to_tensor(lyrics)\n",
        "linguistic = torch.tensor(linguistic)\n",
        "phonetic = phonetic.to('cuda')\n",
        "linguistic = linguistic.to('cuda')\n",
        "phonetic = phonetic.unsqueeze(0)\n",
        "linguistic = linguistic.unsqueeze(0)\n",
        "outputs = net(phonetic, linguistic)\n",
        "outputs = outputs.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "YM34oXF2-YWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ab4d3f-6e66-4b62-a385-da0f114c670b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/PL/linguistic_encoder.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, dtype=torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/output.npy\", outputs)"
      ],
      "metadata": {
        "id": "8vc49LTQ-rEm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_corpus(str1):\n",
        "    res1 = \"\"\n",
        "    for i in str1:\n",
        "        if i.isalpha() or i==\" \":\n",
        "            res1 = res1 + i\n",
        "    return res1.lower().strip().replace(\"  \", \" \")\n",
        "print(lyrics)\n",
        "print(clean_corpus(lyrics))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knUyInRF0Drw",
        "outputId": "b07dcecd-7d7d-4606-f074-5c4ec8c60732"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nửa năm từ khi em ra đi, anh chẳng khác là bao Thuốc thì không hút mấy, nhưng một khi đã hút là nát cả bao Bạn anh hỏi giải pháp là sao? Dạo này không thấy khát và khao? Anh trả lời dạo này chỉ muốn căn nhà 2 đứa có rap và tao ? Mà thôi ông ơi Về Bia rượu thì là tôi không chơi Cố nhắm mắt để ngủ sớm, sáng mai đi tập và sau đó thì là bơi, xông hơi Yeah im feeling so gud Trưa ăn cơm, ban đêm anh ăn soup Làm việc hàng ngày nhưng mà lười một chút Thiền định là vào tầm là mười một phút yeah yeah But u killin me god Yeah yeah Không còn em kế bên Tôi đang làm quen được bao điều hay nhưng sao tôi không thể quên But u killin me god Yeah yeah Không còn em kế bên Tôi đang làm quen được bao điều hay nhưng sao tôi không thể quên Làm sao quến bao đêm xem phim mì gói em nấu I’m fuckin fall in love. Dù cho nó là một thói quen xấu Sau bao nhiêu đêm tôi đã thao thức, vì còn một điều này cần phải giấu I still keep it rollin roll buông ra câu i love u so\n",
            "nửa năm từ khi em ra đi anh chẳng khác là bao thuốc thì không hút mấy nhưng một khi đã hút là nát cả bao bạn anh hỏi giải pháp là sao dạo này không thấy khát và khao anh trả lời dạo này chỉ muốn căn nhà đứa có rap và tao mà thôi ông ơi về bia rượu thì là tôi không chơi cố nhắm mắt để ngủ sớm sáng mai đi tập và sau đó thì là bơi xông hơi yeah im feeling so gud trưa ăn cơm ban đêm anh ăn soup làm việc hàng ngày nhưng mà lười một chút thiền định là vào tầm là mười một phút yeah yeah but u killin me god yeah yeah không còn em kế bên tôi đang làm quen được bao điều hay nhưng sao tôi không thể quên but u killin me god yeah yeah không còn em kế bên tôi đang làm quen được bao điều hay nhưng sao tôi không thể quên làm sao quến bao đêm xem phim mì gói em nấu im fuckin fall in love dù cho nó là một thói quen xấu sau bao nhiêu đêm tôi đã thao thức vì còn một điều này cần phải giấu i still keep it rollin roll buông ra câu i love u so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/output_alignment_fusion/3130303538355f3338.npy\n",
        "# !pip install torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "# import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "# import numpy as np\n",
        "# from char_embedding import tensor_to_text\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "\n",
        "x = np.load(\"/content/output.npy\")\n",
        "\n",
        "# print(x)\n",
        "\n",
        "x = torch.tensor(x)\n",
        "predicted_ids = torch.argmax(torch.tensor(x), dim=1)\n",
        "\n",
        "\n",
        "x = torch.log_softmax(x, dim=-1)\n",
        "x = x.cpu().detach()\n",
        "\n",
        "\n",
        "labels = ('ắ', 'ồ', 'z', 'ứ', 'ỡ', 'ì', 'x', 'ặ', 'u', 'ẹ', 'd', 'ỵ', 'r', 'p', 't', 'ỳ', 'ẩ', 'f', 'ó', 'á', 'v', 'ã', 'i', 'ư', 'ở', 'ễ', 'ụ', 'ú', 'ũ', ' ', 'ă', 'é', 'ằ', 'a', 'ấ', 'ờ', 'ữ', 'ớ', 'n', 'ý', 's', 'h', 'ơ', 'ị', 'l', 'c', 'k', 'ỷ', 'ỗ', 'ế', 'ẻ', 'ợ', 'ẫ', 'í', 'ỏ', 'ủ', 'g', 'q', 'j', 'ò', 'ỹ', 'ự', 'ô', 'b', 'y', 'ĩ', 'ỉ', 'ẵ', 'ầ', 'ê', 'ộ', 'ậ', 'm', 'ń', 'o', 'ọ', 'đ', 'ẽ', 'ử', 'à', 'è', 'e', 'ẳ', 'ổ', 'ù', 'w', 'ả', 'ạ', 'â', 'ệ', 'ề', 'õ', 'ố', 'ể', 'ừ',)\n",
        "\n",
        "# def clean_corpus(str1):\n",
        "#     res1 = \"\"\n",
        "#     for i in str1:\n",
        "#         if i.isalpha() or i==\" \":\n",
        "#             res1 = res1 + i\n",
        "#     return res1.lower().strip().replace(\"  \", \" \")\n",
        "transcript = \" \" + lyrics + \"\"\n",
        "transcript = clean_corpus(transcript)\n",
        "dictionary = {c: i for i, c in enumerate(labels)}\n",
        "\n",
        "tokens = [dictionary[c] for c in transcript]\n",
        "\n",
        "\n",
        "def get_trellis(x, tokens, blank_id=95):\n",
        "    num_frame = x.size(0)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Trellis has extra diemsions for both time axis and tokens.\n",
        "    # The extra dim for tokens represents <SoS> (start-of-sentence)\n",
        "    # The extra dim for time axis is for simplification of the code.\n",
        "    trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
        "    trellis[0, 0] = 0\n",
        "    trellis[1:, 0] = torch.cumsum(x[:, 0], 0)\n",
        "    trellis[0, -num_tokens:] = -float(\"inf\")\n",
        "    trellis[-num_tokens:, 0] = float(\"inf\")\n",
        "\n",
        "    for t in range(num_frame):\n",
        "        trellis[t + 1, 1:] = torch.maximum(\n",
        "            # Score for staying at the same token\n",
        "            trellis[t, 1:] + x[t, blank_id],\n",
        "            # Score for changing to the next token\n",
        "            trellis[t, :-1] + x[t, tokens],\n",
        "        )\n",
        "    return trellis\n",
        "\n",
        "\n",
        "trellis = get_trellis(x, tokens)\n",
        "\n",
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class Point:\n",
        "  token_index: int\n",
        "  time_index: int\n",
        "  score: float\n",
        "\n",
        "\n",
        "def backtrack(trellis, emission, tokens, blank_id=95):\n",
        "  # Note:\n",
        "  # j and t are indices for trellis, which has extra dimensions \n",
        "  # for time and tokens at the beginning.\n",
        "  # When refering to time frame index `T` in trellis,\n",
        "  # the corresponding index in emission is `T-1`.\n",
        "  # Similarly, when refering to token index `J` in trellis,\n",
        "  # the corresponding index in transcript is `J-1`.\n",
        "  j = trellis.size(1) - 1\n",
        "  t_start = torch.argmax(trellis[:, j]).item()\n",
        "\n",
        "  path = []\n",
        "  for t in range(t_start, 0, -1):\n",
        "    # 1. Figure out if the current position was stay or change\n",
        "    # Note (again):\n",
        "    # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n",
        "    # Score for token staying the same from time frame J-1 to T.\n",
        "    stayed = trellis[t-1, j] + emission[t-1, blank_id]\n",
        "    # Score for token changing from C-1 at T-1 to J at T.\n",
        "    changed = trellis[t-1, j-1] + emission[t-1, tokens[j-1]]\n",
        "\n",
        "    # 2. Store the path with frame-wise probability.\n",
        "    prob = emission[t-1, tokens[j-1] if changed > stayed else 0].exp().item()\n",
        "    # Return token index and time index in non-trellis coordinate.\n",
        "    path.append(Point(j-1, t-1, prob))\n",
        "\n",
        "    # 3. Update the token\n",
        "    if changed > stayed:\n",
        "      j -= 1\n",
        "      if j == 0:\n",
        "        break\n",
        "  else:\n",
        "    raise ValueError('Failed to align')\n",
        "  return path[::-1]\n",
        "\n",
        "path = backtrack(trellis, x, tokens)\n",
        "@dataclass\n",
        "class Segment:\n",
        "    label: str\n",
        "    start: int\n",
        "    end: int\n",
        "    score: float\n",
        "    \n",
        "\n",
        "    def __repr__(self):\n",
        "      return f\"{self.start} --> {self.end} {self.label} \\n\"\n",
        "\n",
        "    @property\n",
        "    def length(self):\n",
        "        return self.end - self.start\n",
        "\n",
        "\n",
        "def merge_repeats(path):\n",
        "    i1, i2 = 0, 0\n",
        "    segments = []\n",
        "    while i1 < len(path):\n",
        "        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
        "            i2 += 1\n",
        "        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
        "        segments.append(\n",
        "            Segment(\n",
        "                transcript[path[i1].token_index],\n",
        "                path[i1].time_index,\n",
        "                path[i2 - 1].time_index + 1,\n",
        "                score,\n",
        "            )\n",
        "        )\n",
        "        i1 = i2\n",
        "    return segments\n",
        "\n",
        "\n",
        "segments = merge_repeats(path)\n",
        "\n",
        "# Merge words\n",
        "def merge_words(segments, separator=\" \"):\n",
        "    words = []\n",
        "    i1, i2 = 0, 0\n",
        "    while i1 < len(segments):\n",
        "        if i2 >= len(segments) or segments[i2].label == separator:\n",
        "            if i1 != i2:\n",
        "                segs = segments[i1:i2]\n",
        "                word = \"\".join([seg.label for seg in segs])\n",
        "                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "                words.append(Segment(word, segments[i1].start*20, segments[i2 - 1].end*20, score))\n",
        "            i1 = i2 + 1\n",
        "            i2 = i1\n",
        "        else:\n",
        "            i2 += 1\n",
        "    return words\n",
        "\n",
        "\n",
        "word_segments = merge_words(segments)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcI7rHUh_Bbz",
        "outputId": "16962504-7983-45f9-aed8-0c33c0e10dee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-0cd433317fd5>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  predicted_ids = torch.argmax(torch.tensor(x), dim=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_millis(milliseconds):\n",
        "  millis = milliseconds\n",
        "  millisecond = int(millis%1000)\n",
        "  millisecond = str(millisecond)\n",
        "  if len(millisecond)==0:\n",
        "    millisecond = '000'\n",
        "  elif len(millisecond) == 1:\n",
        "    millisecond = '00' + millisecond\n",
        "  elif len(millisecond) == 2:\n",
        "    millisecond = '0' + millisecond\n",
        "\n",
        "  seconds=(millis/1000)%60\n",
        "  seconds = int(seconds)\n",
        "  seconds = str(seconds)\n",
        "  if len(seconds) == 1:\n",
        "    seconds = '0' + seconds\n",
        "  minutes=(millis/(1000*60))%60\n",
        "  \n",
        "  minutes = int(minutes)\n",
        "  minutes = str(minutes)\n",
        "  if len(minutes) == 1:\n",
        "    minutes = '0' + minutes\n",
        "\n",
        "  hours=(millis/(1000*60*60))%24\n",
        "  hours = int(hours)\n",
        "  hours = str(hours)\n",
        "  if len(hours) == 1:\n",
        "    hours = '0' + hours\n",
        "\n",
        "  return (hours + \":\" + minutes + \":\" +  seconds + \",\" + millisecond)"
      ],
      "metadata": {
        "id": "u5EQ36cu_Dat"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/rap_thoiquen.srt\", \"a\")\n",
        "for i in range(len(word_segments)):\n",
        " \n",
        "  if (i==0):\n",
        "    start = str(str(word_segments[i])).split(\" \")[0]\n",
        "    end_before = int(str(str(word_segments[i])).split(\" \")[2])\n",
        "    word = str(str(word_segments[i])).split(\" \")[3]\n",
        "    if int(start)>=200:\n",
        "      start = int(start)-200\n",
        "    else:\n",
        "      start = 0\n",
        "    start_next = int(str(word_segments[i+1]).split(\" \")[0])\n",
        "    end = (2*end_before + start_next)/3\n",
        "  elif i==len(word_segments)-1:\n",
        "    end_before = int(str(word_segments[i-1]).split(\" \")[2])\n",
        "    start_next = int(str(word_segments[i]).split(\" \")[0])\n",
        "    end = int(str(word_segments[i]).split(\" \")[2]) + 250\n",
        "    start = (2*end_before+start_next)/3\n",
        "    word = str(word_segments[i]).split(\" \")[3]\n",
        "  else:\n",
        "    end_before = int(str(word_segments[i-1]).split(\" \")[2])\n",
        "    start_next = int(str(word_segments[i+1]).split(\" \")[0])\n",
        "    end = int(str(word_segments[i]).split(\" \")[2])\n",
        "    start = int(str(word_segments[i]).split(\" \")[0])\n",
        "    start = (2*end_before+start)/3\n",
        "    end = (2*end + start_next)/3\n",
        "    word = str(word_segments[i]).split(\" \")[3]\n",
        "  \n",
        "  start = (format_millis(start))\n",
        "  end = (format_millis(end))\n",
        "  one_line = str(i+1) + \"\\n\" + start + \" --> \" + end + \"\\n\" + str(word) + \"\\n\\n\"\n",
        "  print(one_line)\n",
        "  f.write(one_line)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaCYVgqQ_Ggq",
        "outputId": "34dc49cd-d2a9-4a44-c483-bf8511a5f92a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "00:00:00,000 --> 00:00:01,146\n",
            "nửa\n",
            "\n",
            "\n",
            "2\n",
            "00:00:01,146 --> 00:00:01,286\n",
            "năm\n",
            "\n",
            "\n",
            "3\n",
            "00:00:01,286 --> 00:00:01,446\n",
            "từ\n",
            "\n",
            "\n",
            "4\n",
            "00:00:01,446 --> 00:00:01,566\n",
            "khi\n",
            "\n",
            "\n",
            "5\n",
            "00:00:01,566 --> 00:00:01,666\n",
            "em\n",
            "\n",
            "\n",
            "6\n",
            "00:00:01,666 --> 00:00:01,853\n",
            "ra\n",
            "\n",
            "\n",
            "7\n",
            "00:00:01,853 --> 00:00:02,646\n",
            "đi\n",
            "\n",
            "\n",
            "8\n",
            "00:00:02,646 --> 00:00:02,886\n",
            "anh\n",
            "\n",
            "\n",
            "9\n",
            "00:00:02,886 --> 00:00:03,086\n",
            "chẳng\n",
            "\n",
            "\n",
            "10\n",
            "00:00:03,086 --> 00:00:03,346\n",
            "khác\n",
            "\n",
            "\n",
            "11\n",
            "00:00:03,346 --> 00:00:03,500\n",
            "là\n",
            "\n",
            "\n",
            "12\n",
            "00:00:03,500 --> 00:00:04,406\n",
            "bao\n",
            "\n",
            "\n",
            "13\n",
            "00:00:04,406 --> 00:00:04,666\n",
            "thuốc\n",
            "\n",
            "\n",
            "14\n",
            "00:00:04,666 --> 00:00:04,826\n",
            "thì\n",
            "\n",
            "\n",
            "15\n",
            "00:00:04,826 --> 00:00:05,033\n",
            "không\n",
            "\n",
            "\n",
            "16\n",
            "00:00:05,033 --> 00:00:05,233\n",
            "hút\n",
            "\n",
            "\n",
            "17\n",
            "00:00:05,233 --> 00:00:05,426\n",
            "mấy\n",
            "\n",
            "\n",
            "18\n",
            "00:00:05,426 --> 00:00:05,566\n",
            "nhưng\n",
            "\n",
            "\n",
            "19\n",
            "00:00:05,566 --> 00:00:05,653\n",
            "một\n",
            "\n",
            "\n",
            "20\n",
            "00:00:05,653 --> 00:00:05,946\n",
            "khi\n",
            "\n",
            "\n",
            "21\n",
            "00:00:05,946 --> 00:00:06,100\n",
            "đã\n",
            "\n",
            "\n",
            "22\n",
            "00:00:06,100 --> 00:00:06,366\n",
            "hút\n",
            "\n",
            "\n",
            "23\n",
            "00:00:06,366 --> 00:00:06,540\n",
            "là\n",
            "\n",
            "\n",
            "24\n",
            "00:00:06,540 --> 00:00:06,780\n",
            "nát\n",
            "\n",
            "\n",
            "25\n",
            "00:00:06,780 --> 00:00:06,953\n",
            "cả\n",
            "\n",
            "\n",
            "26\n",
            "00:00:06,953 --> 00:00:07,366\n",
            "bao\n",
            "\n",
            "\n",
            "27\n",
            "00:00:07,366 --> 00:00:07,660\n",
            "bạn\n",
            "\n",
            "\n",
            "28\n",
            "00:00:07,660 --> 00:00:07,853\n",
            "anh\n",
            "\n",
            "\n",
            "29\n",
            "00:00:07,853 --> 00:00:08,066\n",
            "hỏi\n",
            "\n",
            "\n",
            "30\n",
            "00:00:08,066 --> 00:00:08,266\n",
            "giải\n",
            "\n",
            "\n",
            "31\n",
            "00:00:08,266 --> 00:00:08,526\n",
            "pháp\n",
            "\n",
            "\n",
            "32\n",
            "00:00:08,526 --> 00:00:08,706\n",
            "là\n",
            "\n",
            "\n",
            "33\n",
            "00:00:08,706 --> 00:00:09,093\n",
            "sao\n",
            "\n",
            "\n",
            "34\n",
            "00:00:09,093 --> 00:00:09,426\n",
            "dạo\n",
            "\n",
            "\n",
            "35\n",
            "00:00:09,426 --> 00:00:09,566\n",
            "này\n",
            "\n",
            "\n",
            "36\n",
            "00:00:09,566 --> 00:00:09,780\n",
            "không\n",
            "\n",
            "\n",
            "37\n",
            "00:00:09,780 --> 00:00:09,986\n",
            "thấy\n",
            "\n",
            "\n",
            "38\n",
            "00:00:09,986 --> 00:00:10,266\n",
            "khát\n",
            "\n",
            "\n",
            "39\n",
            "00:00:10,266 --> 00:00:10,426\n",
            "và\n",
            "\n",
            "\n",
            "40\n",
            "00:00:10,426 --> 00:00:10,846\n",
            "khao\n",
            "\n",
            "\n",
            "41\n",
            "00:00:10,846 --> 00:00:11,106\n",
            "anh\n",
            "\n",
            "\n",
            "42\n",
            "00:00:11,106 --> 00:00:11,273\n",
            "trả\n",
            "\n",
            "\n",
            "43\n",
            "00:00:11,273 --> 00:00:11,480\n",
            "lời\n",
            "\n",
            "\n",
            "44\n",
            "00:00:11,480 --> 00:00:11,686\n",
            "dạo\n",
            "\n",
            "\n",
            "45\n",
            "00:00:11,686 --> 00:00:11,906\n",
            "này\n",
            "\n",
            "\n",
            "46\n",
            "00:00:11,906 --> 00:00:12,066\n",
            "chỉ\n",
            "\n",
            "\n",
            "47\n",
            "00:00:12,066 --> 00:00:12,286\n",
            "muốn\n",
            "\n",
            "\n",
            "48\n",
            "00:00:12,286 --> 00:00:12,480\n",
            "căn\n",
            "\n",
            "\n",
            "49\n",
            "00:00:12,480 --> 00:00:12,773\n",
            "nhà\n",
            "\n",
            "\n",
            "50\n",
            "00:00:12,773 --> 00:00:13,133\n",
            "đứa\n",
            "\n",
            "\n",
            "51\n",
            "00:00:13,133 --> 00:00:13,313\n",
            "có\n",
            "\n",
            "\n",
            "52\n",
            "00:00:13,313 --> 00:00:13,606\n",
            "rap\n",
            "\n",
            "\n",
            "53\n",
            "00:00:13,606 --> 00:00:13,766\n",
            "và\n",
            "\n",
            "\n",
            "54\n",
            "00:00:13,766 --> 00:00:14,013\n",
            "tao\n",
            "\n",
            "\n",
            "55\n",
            "00:00:14,013 --> 00:00:14,186\n",
            "mà\n",
            "\n",
            "\n",
            "56\n",
            "00:00:14,186 --> 00:00:14,506\n",
            "thôi\n",
            "\n",
            "\n",
            "57\n",
            "00:00:14,506 --> 00:00:14,840\n",
            "ông\n",
            "\n",
            "\n",
            "58\n",
            "00:00:14,840 --> 00:00:15,286\n",
            "ơi\n",
            "\n",
            "\n",
            "59\n",
            "00:00:15,286 --> 00:00:15,466\n",
            "về\n",
            "\n",
            "\n",
            "60\n",
            "00:00:15,466 --> 00:00:15,586\n",
            "bia\n",
            "\n",
            "\n",
            "61\n",
            "00:00:15,586 --> 00:00:15,746\n",
            "rượu\n",
            "\n",
            "\n",
            "62\n",
            "00:00:15,746 --> 00:00:15,873\n",
            "thì\n",
            "\n",
            "\n",
            "63\n",
            "00:00:15,873 --> 00:00:16,006\n",
            "là\n",
            "\n",
            "\n",
            "64\n",
            "00:00:16,006 --> 00:00:16,226\n",
            "tôi\n",
            "\n",
            "\n",
            "65\n",
            "00:00:16,226 --> 00:00:16,626\n",
            "không\n",
            "\n",
            "\n",
            "66\n",
            "00:00:16,626 --> 00:00:16,986\n",
            "chơi\n",
            "\n",
            "\n",
            "67\n",
            "00:00:16,986 --> 00:00:17,166\n",
            "cố\n",
            "\n",
            "\n",
            "68\n",
            "00:00:17,166 --> 00:00:17,293\n",
            "nhắm\n",
            "\n",
            "\n",
            "69\n",
            "00:00:17,293 --> 00:00:17,426\n",
            "mắt\n",
            "\n",
            "\n",
            "70\n",
            "00:00:17,426 --> 00:00:17,526\n",
            "để\n",
            "\n",
            "\n",
            "71\n",
            "00:00:17,526 --> 00:00:17,706\n",
            "ngủ\n",
            "\n",
            "\n",
            "72\n",
            "00:00:17,706 --> 00:00:18,053\n",
            "sớm\n",
            "\n",
            "\n",
            "73\n",
            "00:00:18,053 --> 00:00:18,286\n",
            "sáng\n",
            "\n",
            "\n",
            "74\n",
            "00:00:18,286 --> 00:00:18,406\n",
            "mai\n",
            "\n",
            "\n",
            "75\n",
            "00:00:18,406 --> 00:00:18,533\n",
            "đi\n",
            "\n",
            "\n",
            "76\n",
            "00:00:18,533 --> 00:00:18,686\n",
            "tập\n",
            "\n",
            "\n",
            "77\n",
            "00:00:18,686 --> 00:00:18,806\n",
            "và\n",
            "\n",
            "\n",
            "78\n",
            "00:00:18,806 --> 00:00:18,966\n",
            "sau\n",
            "\n",
            "\n",
            "79\n",
            "00:00:18,966 --> 00:00:19,106\n",
            "đó\n",
            "\n",
            "\n",
            "80\n",
            "00:00:19,106 --> 00:00:19,246\n",
            "thì\n",
            "\n",
            "\n",
            "81\n",
            "00:00:19,246 --> 00:00:19,373\n",
            "là\n",
            "\n",
            "\n",
            "82\n",
            "00:00:19,373 --> 00:00:19,706\n",
            "bơi\n",
            "\n",
            "\n",
            "83\n",
            "00:00:19,706 --> 00:00:20,033\n",
            "xông\n",
            "\n",
            "\n",
            "84\n",
            "00:00:20,033 --> 00:00:20,413\n",
            "hơi\n",
            "\n",
            "\n",
            "85\n",
            "00:00:20,413 --> 00:00:20,566\n",
            "yeah\n",
            "\n",
            "\n",
            "86\n",
            "00:00:20,566 --> 00:00:20,646\n",
            "im\n",
            "\n",
            "\n",
            "87\n",
            "00:00:20,646 --> 00:00:20,926\n",
            "feeling\n",
            "\n",
            "\n",
            "88\n",
            "00:00:20,926 --> 00:00:21,146\n",
            "so\n",
            "\n",
            "\n",
            "89\n",
            "00:00:21,146 --> 00:00:21,513\n",
            "gud\n",
            "\n",
            "\n",
            "90\n",
            "00:00:21,513 --> 00:00:21,786\n",
            "trưa\n",
            "\n",
            "\n",
            "91\n",
            "00:00:21,786 --> 00:00:21,953\n",
            "ăn\n",
            "\n",
            "\n",
            "92\n",
            "00:00:21,953 --> 00:00:22,186\n",
            "cơm\n",
            "\n",
            "\n",
            "93\n",
            "00:00:22,186 --> 00:00:22,366\n",
            "ban\n",
            "\n",
            "\n",
            "94\n",
            "00:00:22,366 --> 00:00:22,526\n",
            "đêm\n",
            "\n",
            "\n",
            "95\n",
            "00:00:22,526 --> 00:00:22,686\n",
            "anh\n",
            "\n",
            "\n",
            "96\n",
            "00:00:22,686 --> 00:00:22,806\n",
            "ăn\n",
            "\n",
            "\n",
            "97\n",
            "00:00:22,806 --> 00:00:23,200\n",
            "soup\n",
            "\n",
            "\n",
            "98\n",
            "00:00:23,200 --> 00:00:23,386\n",
            "làm\n",
            "\n",
            "\n",
            "99\n",
            "00:00:23,386 --> 00:00:23,506\n",
            "việc\n",
            "\n",
            "\n",
            "100\n",
            "00:00:23,506 --> 00:00:23,666\n",
            "hàng\n",
            "\n",
            "\n",
            "101\n",
            "00:00:23,666 --> 00:00:23,826\n",
            "ngày\n",
            "\n",
            "\n",
            "102\n",
            "00:00:23,826 --> 00:00:23,973\n",
            "nhưng\n",
            "\n",
            "\n",
            "103\n",
            "00:00:23,973 --> 00:00:24,106\n",
            "mà\n",
            "\n",
            "\n",
            "104\n",
            "00:00:24,106 --> 00:00:24,393\n",
            "lười\n",
            "\n",
            "\n",
            "105\n",
            "00:00:24,393 --> 00:00:24,540\n",
            "một\n",
            "\n",
            "\n",
            "106\n",
            "00:00:24,540 --> 00:00:24,800\n",
            "chút\n",
            "\n",
            "\n",
            "107\n",
            "00:00:24,800 --> 00:00:25,086\n",
            "thiền\n",
            "\n",
            "\n",
            "108\n",
            "00:00:25,086 --> 00:00:25,253\n",
            "định\n",
            "\n",
            "\n",
            "109\n",
            "00:00:25,253 --> 00:00:25,386\n",
            "là\n",
            "\n",
            "\n",
            "110\n",
            "00:00:25,386 --> 00:00:25,666\n",
            "vào\n",
            "\n",
            "\n",
            "111\n",
            "00:00:25,666 --> 00:00:25,786\n",
            "tầm\n",
            "\n",
            "\n",
            "112\n",
            "00:00:25,786 --> 00:00:25,846\n",
            "là\n",
            "\n",
            "\n",
            "113\n",
            "00:00:25,846 --> 00:00:26,046\n",
            "mười\n",
            "\n",
            "\n",
            "114\n",
            "00:00:26,046 --> 00:00:26,240\n",
            "một\n",
            "\n",
            "\n",
            "115\n",
            "00:00:26,240 --> 00:00:26,506\n",
            "phút\n",
            "\n",
            "\n",
            "116\n",
            "00:00:26,506 --> 00:00:26,753\n",
            "yeah\n",
            "\n",
            "\n",
            "117\n",
            "00:00:26,753 --> 00:00:26,966\n",
            "yeah\n",
            "\n",
            "\n",
            "118\n",
            "00:00:26,966 --> 00:00:27,340\n",
            "but\n",
            "\n",
            "\n",
            "119\n",
            "00:00:27,340 --> 00:00:27,466\n",
            "u\n",
            "\n",
            "\n",
            "120\n",
            "00:00:27,466 --> 00:00:27,753\n",
            "killin\n",
            "\n",
            "\n",
            "121\n",
            "00:00:27,753 --> 00:00:27,933\n",
            "me\n",
            "\n",
            "\n",
            "122\n",
            "00:00:27,933 --> 00:00:28,253\n",
            "god\n",
            "\n",
            "\n",
            "123\n",
            "00:00:28,253 --> 00:00:28,580\n",
            "yeah\n",
            "\n",
            "\n",
            "124\n",
            "00:00:28,580 --> 00:00:29,306\n",
            "yeah\n",
            "\n",
            "\n",
            "125\n",
            "00:00:29,306 --> 00:00:29,473\n",
            "không\n",
            "\n",
            "\n",
            "126\n",
            "00:00:29,473 --> 00:00:29,693\n",
            "còn\n",
            "\n",
            "\n",
            "127\n",
            "00:00:29,693 --> 00:00:29,986\n",
            "em\n",
            "\n",
            "\n",
            "128\n",
            "00:00:29,986 --> 00:00:30,260\n",
            "kế\n",
            "\n",
            "\n",
            "129\n",
            "00:00:30,260 --> 00:00:30,586\n",
            "bên\n",
            "\n",
            "\n",
            "130\n",
            "00:00:30,586 --> 00:00:30,973\n",
            "tôi\n",
            "\n",
            "\n",
            "131\n",
            "00:00:30,973 --> 00:00:31,213\n",
            "đang\n",
            "\n",
            "\n",
            "132\n",
            "00:00:31,213 --> 00:00:31,393\n",
            "làm\n",
            "\n",
            "\n",
            "133\n",
            "00:00:31,393 --> 00:00:31,666\n",
            "quen\n",
            "\n",
            "\n",
            "134\n",
            "00:00:31,666 --> 00:00:31,826\n",
            "được\n",
            "\n",
            "\n",
            "135\n",
            "00:00:31,826 --> 00:00:32,066\n",
            "bao\n",
            "\n",
            "\n",
            "136\n",
            "00:00:32,066 --> 00:00:32,333\n",
            "điều\n",
            "\n",
            "\n",
            "137\n",
            "00:00:32,333 --> 00:00:32,480\n",
            "hay\n",
            "\n",
            "\n",
            "138\n",
            "00:00:32,480 --> 00:00:32,726\n",
            "nhưng\n",
            "\n",
            "\n",
            "139\n",
            "00:00:32,726 --> 00:00:32,940\n",
            "sao\n",
            "\n",
            "\n",
            "140\n",
            "00:00:32,940 --> 00:00:33,126\n",
            "tôi\n",
            "\n",
            "\n",
            "141\n",
            "00:00:33,126 --> 00:00:33,346\n",
            "không\n",
            "\n",
            "\n",
            "142\n",
            "00:00:33,346 --> 00:00:33,726\n",
            "thể\n",
            "\n",
            "\n",
            "143\n",
            "00:00:33,726 --> 00:00:33,960\n",
            "quên\n",
            "\n",
            "\n",
            "144\n",
            "00:00:33,960 --> 00:00:34,193\n",
            "but\n",
            "\n",
            "\n",
            "145\n",
            "00:00:34,193 --> 00:00:34,326\n",
            "u\n",
            "\n",
            "\n",
            "146\n",
            "00:00:34,326 --> 00:00:34,606\n",
            "killin\n",
            "\n",
            "\n",
            "147\n",
            "00:00:34,606 --> 00:00:34,773\n",
            "me\n",
            "\n",
            "\n",
            "148\n",
            "00:00:34,773 --> 00:00:35,053\n",
            "god\n",
            "\n",
            "\n",
            "149\n",
            "00:00:35,053 --> 00:00:35,473\n",
            "yeah\n",
            "\n",
            "\n",
            "150\n",
            "00:00:35,473 --> 00:00:35,886\n",
            "yeah\n",
            "\n",
            "\n",
            "151\n",
            "00:00:35,886 --> 00:00:36,353\n",
            "không\n",
            "\n",
            "\n",
            "152\n",
            "00:00:36,353 --> 00:00:36,566\n",
            "còn\n",
            "\n",
            "\n",
            "153\n",
            "00:00:36,566 --> 00:00:36,846\n",
            "em\n",
            "\n",
            "\n",
            "154\n",
            "00:00:36,846 --> 00:00:37,120\n",
            "kế\n",
            "\n",
            "\n",
            "155\n",
            "00:00:37,120 --> 00:00:37,446\n",
            "bên\n",
            "\n",
            "\n",
            "156\n",
            "00:00:37,446 --> 00:00:37,833\n",
            "tôi\n",
            "\n",
            "\n",
            "157\n",
            "00:00:37,833 --> 00:00:38,046\n",
            "đang\n",
            "\n",
            "\n",
            "158\n",
            "00:00:38,046 --> 00:00:38,240\n",
            "làm\n",
            "\n",
            "\n",
            "159\n",
            "00:00:38,240 --> 00:00:38,500\n",
            "quen\n",
            "\n",
            "\n",
            "160\n",
            "00:00:38,500 --> 00:00:38,726\n",
            "được\n",
            "\n",
            "\n",
            "161\n",
            "00:00:38,726 --> 00:00:38,926\n",
            "bao\n",
            "\n",
            "\n",
            "162\n",
            "00:00:38,926 --> 00:00:39,133\n",
            "điều\n",
            "\n",
            "\n",
            "163\n",
            "00:00:39,133 --> 00:00:39,366\n",
            "hay\n",
            "\n",
            "\n",
            "164\n",
            "00:00:39,366 --> 00:00:39,540\n",
            "nhưng\n",
            "\n",
            "\n",
            "165\n",
            "00:00:39,540 --> 00:00:39,780\n",
            "sao\n",
            "\n",
            "\n",
            "166\n",
            "00:00:39,780 --> 00:00:39,986\n",
            "tôi\n",
            "\n",
            "\n",
            "167\n",
            "00:00:39,986 --> 00:00:40,200\n",
            "không\n",
            "\n",
            "\n",
            "168\n",
            "00:00:40,200 --> 00:00:40,473\n",
            "thể\n",
            "\n",
            "\n",
            "169\n",
            "00:00:40,473 --> 00:00:41,006\n",
            "quên\n",
            "\n",
            "\n",
            "170\n",
            "00:00:41,006 --> 00:00:41,200\n",
            "làm\n",
            "\n",
            "\n",
            "171\n",
            "00:00:41,200 --> 00:00:41,506\n",
            "sao\n",
            "\n",
            "\n",
            "172\n",
            "00:00:41,506 --> 00:00:41,866\n",
            "quến\n",
            "\n",
            "\n",
            "173\n",
            "00:00:41,866 --> 00:00:42,066\n",
            "bao\n",
            "\n",
            "\n",
            "174\n",
            "00:00:42,066 --> 00:00:42,286\n",
            "đêm\n",
            "\n",
            "\n",
            "175\n",
            "00:00:42,286 --> 00:00:42,460\n",
            "xem\n",
            "\n",
            "\n",
            "176\n",
            "00:00:42,460 --> 00:00:42,706\n",
            "phim\n",
            "\n",
            "\n",
            "177\n",
            "00:00:42,706 --> 00:00:42,920\n",
            "mì\n",
            "\n",
            "\n",
            "178\n",
            "00:00:42,920 --> 00:00:43,160\n",
            "gói\n",
            "\n",
            "\n",
            "179\n",
            "00:00:43,160 --> 00:00:43,326\n",
            "em\n",
            "\n",
            "\n",
            "180\n",
            "00:00:43,326 --> 00:00:43,966\n",
            "nấu\n",
            "\n",
            "\n",
            "181\n",
            "00:00:43,966 --> 00:00:44,206\n",
            "im\n",
            "\n",
            "\n",
            "182\n",
            "00:00:44,206 --> 00:00:44,620\n",
            "fuckin\n",
            "\n",
            "\n",
            "183\n",
            "00:00:44,620 --> 00:00:44,960\n",
            "fall\n",
            "\n",
            "\n",
            "184\n",
            "00:00:44,960 --> 00:00:45,073\n",
            "in\n",
            "\n",
            "\n",
            "185\n",
            "00:00:45,073 --> 00:00:45,306\n",
            "love\n",
            "\n",
            "\n",
            "186\n",
            "00:00:45,306 --> 00:00:45,526\n",
            "dù\n",
            "\n",
            "\n",
            "187\n",
            "00:00:45,526 --> 00:00:45,720\n",
            "cho\n",
            "\n",
            "\n",
            "188\n",
            "00:00:45,720 --> 00:00:45,920\n",
            "nó\n",
            "\n",
            "\n",
            "189\n",
            "00:00:45,920 --> 00:00:46,160\n",
            "là\n",
            "\n",
            "\n",
            "190\n",
            "00:00:46,160 --> 00:00:46,373\n",
            "một\n",
            "\n",
            "\n",
            "191\n",
            "00:00:46,373 --> 00:00:46,560\n",
            "thói\n",
            "\n",
            "\n",
            "192\n",
            "00:00:46,560 --> 00:00:46,786\n",
            "quen\n",
            "\n",
            "\n",
            "193\n",
            "00:00:46,786 --> 00:00:47,213\n",
            "xấu\n",
            "\n",
            "\n",
            "194\n",
            "00:00:47,213 --> 00:00:47,386\n",
            "sau\n",
            "\n",
            "\n",
            "195\n",
            "00:00:47,386 --> 00:00:47,506\n",
            "bao\n",
            "\n",
            "\n",
            "196\n",
            "00:00:47,506 --> 00:00:47,666\n",
            "nhiêu\n",
            "\n",
            "\n",
            "197\n",
            "00:00:47,666 --> 00:00:47,966\n",
            "đêm\n",
            "\n",
            "\n",
            "198\n",
            "00:00:47,966 --> 00:00:48,093\n",
            "tôi\n",
            "\n",
            "\n",
            "199\n",
            "00:00:48,093 --> 00:00:48,366\n",
            "đã\n",
            "\n",
            "\n",
            "200\n",
            "00:00:48,366 --> 00:00:48,533\n",
            "thao\n",
            "\n",
            "\n",
            "201\n",
            "00:00:48,533 --> 00:00:48,760\n",
            "thức\n",
            "\n",
            "\n",
            "202\n",
            "00:00:48,760 --> 00:00:48,940\n",
            "vì\n",
            "\n",
            "\n",
            "203\n",
            "00:00:48,940 --> 00:00:49,173\n",
            "còn\n",
            "\n",
            "\n",
            "204\n",
            "00:00:49,173 --> 00:00:49,366\n",
            "một\n",
            "\n",
            "\n",
            "205\n",
            "00:00:49,366 --> 00:00:49,646\n",
            "điều\n",
            "\n",
            "\n",
            "206\n",
            "00:00:49,646 --> 00:00:49,800\n",
            "này\n",
            "\n",
            "\n",
            "207\n",
            "00:00:49,800 --> 00:00:50,013\n",
            "cần\n",
            "\n",
            "\n",
            "208\n",
            "00:00:50,013 --> 00:00:50,213\n",
            "phải\n",
            "\n",
            "\n",
            "209\n",
            "00:00:50,213 --> 00:00:50,506\n",
            "giấu\n",
            "\n",
            "\n",
            "210\n",
            "00:00:50,506 --> 00:00:50,626\n",
            "i\n",
            "\n",
            "\n",
            "211\n",
            "00:00:50,626 --> 00:00:51,086\n",
            "still\n",
            "\n",
            "\n",
            "212\n",
            "00:00:51,086 --> 00:00:51,373\n",
            "keep\n",
            "\n",
            "\n",
            "213\n",
            "00:00:51,373 --> 00:00:51,566\n",
            "it\n",
            "\n",
            "\n",
            "214\n",
            "00:00:51,566 --> 00:00:51,960\n",
            "rollin\n",
            "\n",
            "\n",
            "215\n",
            "00:00:51,960 --> 00:00:52,206\n",
            "roll\n",
            "\n",
            "\n",
            "216\n",
            "00:00:52,206 --> 00:00:52,626\n",
            "buông\n",
            "\n",
            "\n",
            "217\n",
            "00:00:52,626 --> 00:00:52,806\n",
            "ra\n",
            "\n",
            "\n",
            "218\n",
            "00:00:52,806 --> 00:00:53,073\n",
            "câu\n",
            "\n",
            "\n",
            "219\n",
            "00:00:53,073 --> 00:00:53,240\n",
            "i\n",
            "\n",
            "\n",
            "220\n",
            "00:00:53,240 --> 00:00:53,606\n",
            "love\n",
            "\n",
            "\n",
            "221\n",
            "00:00:53,606 --> 00:00:53,666\n",
            "u\n",
            "\n",
            "\n",
            "222\n",
            "00:00:53,666 --> 00:00:54,110\n",
            "so\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !ffmpeg -i /content/lyric_align.jpg -i \"/content/test.wav\" -sub_charenc utf-8 -i \"/content/yeuyeuyeu.srt\" \"/content/OUTPUT.mp4\""
      ],
      "metadata": {
        "id": "uPQuNbKWD9Om"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i /content/test.mp4 -sub_charenc utf-8 -i \"/content/rap_thoiquen.srt\" \"/content/OUTPUT.mp4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtIV4r6o5_Jj",
        "outputId": "52c35572-4edc-4705-9c5d-402f4eee0e6e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/test.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2022-03-13T02:48:03.000000Z\n",
            "  Duration: 00:00:56.63, start: 0.000000, bitrate: 628 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 406x720 [SAR 1:1 DAR 203:360], 496 kb/s, 29.78 fps, 29.78 tbr, 14891 tbn, 59.56 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-03-13T02:48:03.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/12/2022.\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-03-13T02:48:03.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/12/2022.\n",
            "Input #1, srt, from '/content/rap_thoiquen.srt':\n",
            "  Duration: N/A, bitrate: N/A\n",
            "    Stream #1:0: Subtitle: subrip\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
            "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mprofile High, level 3.0\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/OUTPUT.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    encoder         : Lavf58.29.100\n",
            "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 406x720 [SAR 1:1 DAR 203:360], q=-1--1, 29.78 fps, 14891 tbn, 29.78 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-03-13T02:48:03.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/12/2022.\n",
            "      encoder         : Lavc58.54.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-03-13T02:48:03.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 03/12/2022.\n",
            "      encoder         : Lavc58.54.100 aac\n",
            "frame= 1686 fps= 54 q=-1.0 Lsize=    5489kB time=00:00:56.63 bitrate= 793.9kbits/s speed=1.83x    \n",
            "video:4534kB audio:893kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.132865%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mframe I:7     Avg QP:20.02  size: 35799\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mframe P:425   Avg QP:22.61  size:  7249\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mframe B:1254  Avg QP:27.62  size:  1045\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mconsecutive B-frames:  0.6%  0.4%  1.1% 98.0%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mmb I  I16..4: 12.0% 46.9% 41.1%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mmb P  I16..4:  3.6%  3.3%  0.8%  P16..4: 50.2% 15.2%  8.3%  0.0%  0.0%    skip:18.6%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mmb B  I16..4:  0.3%  0.3%  0.0%  B16..8: 49.1%  2.0%  0.3%  direct: 0.5%  skip:47.4%  L0:49.5% L1:47.3% BI: 3.2%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0m8x8 transform intra:43.7% inter:63.7%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mcoded y,uvDC,uvAC intra: 30.3% 60.8% 26.8% inter: 8.8% 8.8% 1.7%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mi16 v,h,dc,p: 20% 29% 20% 31%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 29% 34%  2%  2%  2%  3%  2%  3%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 37% 16%  3%  3%  3%  5%  3%  3%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mi8c dc,h,v,p: 45% 29% 22%  4%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mWeighted P-Frames: Y:4.9% UV:0.7%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mref P L0: 53.2% 15.1% 18.2% 13.0%  0.5%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mref B L0: 81.7% 15.0%  3.3%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mref B L1: 90.9%  9.1%\n",
            "\u001b[1;36m[libx264 @ 0x559385694000] \u001b[0mkb/s:655.94\n",
            "\u001b[1;36m[aac @ 0x559385694d80] \u001b[0mQavg: 216.745\n"
          ]
        }
      ]
    }
  ]
}