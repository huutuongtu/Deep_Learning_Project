{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "L8gAKidmPJ4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb3ed4f-bce0-49d9-816d-55ddf6e355cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# cd /content/drive/MyDrive/PL"
      ],
      "metadata": {
        "id": "yJTrbWGMQ4Mo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63S9MelmZxkv",
        "outputId": "50648191-c3c1-4bd4-b5d3-f85aa74d1c9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/PL/meta_data_public_test.csv')\n",
        "print((data['Wav_Path'][0].split(\"/\")[7]).split(\".\")[0] + \".npy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-MertGdZQS-",
        "outputId": "33b335c6-17cb-4fd2-fc3f-28d8ee914461"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37333433375f3638.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qwlQhYw_8VxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20ff814-9a14-4a73-f689-208bfcad3e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-448198f8689f>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  predicted_ids = torch.argmax(torch.tensor(x), dim=1)\n"
          ]
        }
      ],
      "source": [
        "# /content/drive/MyDrive/output_alignment_fusion/3130303538355f3338.npy\n",
        "!pip install torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "# import numpy as np\n",
        "# from char_embedding import tensor_to_text\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "base_dir = '/content/drive/MyDrive/song_phonetic/'\n",
        "# pat = glob.glob('/content/drive/MyDrive/output_alignment/*.npy')\n",
        "last_output = []\n",
        "PA = []\n",
        "for i in range(len(data)):\n",
        "  tu = str(base_dir) + data['Wav_Path'][i].split(\"/\")[7].split(\".\")[0] + \".npy\"\n",
        "  PA.append(tu)\n",
        "  x = np.load(tu)\n",
        "\n",
        "  # print(x)\n",
        "\n",
        "  x = torch.tensor(x)\n",
        "  predicted_ids = torch.argmax(torch.tensor(x), dim=1)\n",
        "\n",
        "\n",
        "  x = torch.log_softmax(x, dim=-1)\n",
        "  x = x.cpu().detach()\n",
        "\n",
        "\n",
        "  labels = ('ắ', 'ồ', 'z', 'ứ', 'ỡ', 'ì', 'x', 'ặ', 'u', 'ẹ', 'd', 'ỵ', 'r', 'p', 't', 'ỳ', 'ẩ', 'f', 'ó', 'á', 'v', 'ã', 'i', 'ư', 'ở', 'ễ', 'ụ', 'ú', 'ũ', ' ', 'ă', 'é', 'ằ', 'a', 'ấ', 'ờ', 'ữ', 'ớ', 'n', 'ý', 's', 'h', 'ơ', 'ị', 'l', 'c', 'k', 'ỷ', 'ỗ', 'ế', 'ẻ', 'ợ', 'ẫ', 'í', 'ỏ', 'ủ', 'g', 'q', 'j', 'ò', 'ỹ', 'ự', 'ô', 'b', 'y', 'ĩ', 'ỉ', 'ẵ', 'ầ', 'ê', 'ộ', 'ậ', 'm', 'ń', 'o', 'ọ', 'đ', 'ẽ', 'ử', 'à', 'è', 'e', 'ẳ', 'ổ', 'ù', 'w', 'ả', 'ạ', 'â', 'ệ', 'ề', 'õ', 'ố', 'ể', 'ừ',)\n",
        "\n",
        "  def clean_corpus(str1):\n",
        "      res1 = \"\"\n",
        "      for i in str1:\n",
        "          if i.isalpha() or i==\" \":\n",
        "              res1 = \"\".join([res1, i])\n",
        "      return res1.lower()\n",
        "  transcript = \" \" + str(data['Lyric_Path'][i]) + \"\"\n",
        "  transcript = clean_corpus(transcript)\n",
        "  dictionary = {c: i for i, c in enumerate(labels)}\n",
        "\n",
        "  tokens = [dictionary[c] for c in transcript]\n",
        "\n",
        "\n",
        "  def get_trellis(x, tokens, blank_id=95):\n",
        "      num_frame = x.size(0)\n",
        "      num_tokens = len(tokens)\n",
        "\n",
        "      # Trellis has extra diemsions for both time axis and tokens.\n",
        "      # The extra dim for tokens represents <SoS> (start-of-sentence)\n",
        "      # The extra dim for time axis is for simplification of the code.\n",
        "      trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
        "      trellis[0, 0] = 0\n",
        "      trellis[1:, 0] = torch.cumsum(x[:, 0], 0)\n",
        "      trellis[0, -num_tokens:] = -float(\"inf\")\n",
        "      trellis[-num_tokens:, 0] = float(\"inf\")\n",
        "\n",
        "      for t in range(num_frame):\n",
        "          trellis[t + 1, 1:] = torch.maximum(\n",
        "              # Score for staying at the same token\n",
        "              trellis[t, 1:] + x[t, blank_id],\n",
        "              # Score for changing to the next token\n",
        "              trellis[t, :-1] + x[t, tokens],\n",
        "          )\n",
        "      return trellis\n",
        "\n",
        "\n",
        "  trellis = get_trellis(x, tokens)\n",
        "\n",
        "  from dataclasses import dataclass\n",
        "  @dataclass\n",
        "  class Point:\n",
        "    token_index: int\n",
        "    time_index: int\n",
        "    score: float\n",
        "\n",
        "\n",
        "  def backtrack(trellis, emission, tokens, blank_id=95):\n",
        "    # Note:\n",
        "    # j and t are indices for trellis, which has extra dimensions \n",
        "    # for time and tokens at the beginning.\n",
        "    # When refering to time frame index `T` in trellis,\n",
        "    # the corresponding index in emission is `T-1`.\n",
        "    # Similarly, when refering to token index `J` in trellis,\n",
        "    # the corresponding index in transcript is `J-1`.\n",
        "    j = trellis.size(1) - 1\n",
        "    t_start = torch.argmax(trellis[:, j]).item()\n",
        "\n",
        "    path = []\n",
        "    for t in range(t_start, 0, -1):\n",
        "      # 1. Figure out if the current position was stay or change\n",
        "      # Note (again):\n",
        "      # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n",
        "      # Score for token staying the same from time frame J-1 to T.\n",
        "      stayed = trellis[t-1, j] + emission[t-1, blank_id]\n",
        "      # Score for token changing from C-1 at T-1 to J at T.\n",
        "      changed = trellis[t-1, j-1] + emission[t-1, tokens[j-1]]\n",
        "\n",
        "      # 2. Store the path with frame-wise probability.\n",
        "      prob = emission[t-1, tokens[j-1] if changed > stayed else 0].exp().item()\n",
        "      # Return token index and time index in non-trellis coordinate.\n",
        "      path.append(Point(j-1, t-1, prob))\n",
        "\n",
        "      # 3. Update the token\n",
        "      if changed > stayed:\n",
        "        j -= 1\n",
        "        if j == 0:\n",
        "          break\n",
        "    else:\n",
        "      raise ValueError('Failed to align')\n",
        "    return path[::-1]\n",
        "\n",
        "  path = backtrack(trellis, x, tokens)\n",
        "  @dataclass\n",
        "  class Segment:\n",
        "      label: str\n",
        "      start: int\n",
        "      end: int\n",
        "      score: float\n",
        "      \n",
        "\n",
        "      def __repr__(self):\n",
        "        return f\"{self.label}\\t({self.score:4.2f}): [{self.start:5d}, {self.end:5d})\"\n",
        "\n",
        "      @property\n",
        "      def length(self):\n",
        "          return self.end - self.start\n",
        "\n",
        "\n",
        "  def merge_repeats(path):\n",
        "      i1, i2 = 0, 0\n",
        "      segments = []\n",
        "      while i1 < len(path):\n",
        "          while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
        "              i2 += 1\n",
        "          score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
        "          segments.append(\n",
        "              Segment(\n",
        "                  transcript[path[i1].token_index],\n",
        "                  path[i1].time_index,\n",
        "                  path[i2 - 1].time_index + 1,\n",
        "                  score,\n",
        "              )\n",
        "          )\n",
        "          i1 = i2\n",
        "      return segments\n",
        "\n",
        "\n",
        "  segments = merge_repeats(path)\n",
        "\n",
        "  # Merge words\n",
        "  def merge_words(segments, separator=\" \"):\n",
        "      words = []\n",
        "      i1, i2 = 0, 0\n",
        "      while i1 < len(segments):\n",
        "          if i2 >= len(segments) or segments[i2].label == separator:\n",
        "              if i1 != i2:\n",
        "                  segs = segments[i1:i2]\n",
        "                  word = \"\".join([seg.label for seg in segs])\n",
        "                  score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "                  words.append(Segment(word, segments[i1].start*20, segments[i2 - 1].end*20, score))\n",
        "              i1 = i2 + 1\n",
        "              i2 = i1\n",
        "          else:\n",
        "              i2 += 1\n",
        "      return words\n",
        "\n",
        "\n",
        "  word_segments = merge_words(segments)\n",
        "  last_output.append(word_segments)\n",
        "data = pd.DataFrame([PA,last_output])\n",
        "data = data.transpose() #To Transpose and make each rows as columns\n",
        "data.columns=['Path','Output']\n",
        "data.to_csv('/content/drive/MyDrive/PL/song_output.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('/content/drive/MyDrive/PL/vocal_output.csv')"
      ],
      "metadata": {
        "id": "vQsq4gneboKc"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}