{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfbyhs-xp9M_",
        "outputId": "00dcab4a-af35-4234-ee89-fce7fba6e696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPvmE2N2qVp7",
        "outputId": "002d44db-003a-4373-b11d-ac251e1ac54a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install cmath\n",
        "!pip install torch\n",
        "!pip install sklearn\n",
        "!pip install pandas\n",
        "!pip install librosa\n",
        "!pip install numpy\n",
        "!pip install speechpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu8J17eyqNCg",
        "outputId": "2b26bfcd-a86f-4a60-e976-66d10b93ebb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=2bab7c077ef4718501b66322edc55ce7dcb98bfabcc951a9be7881769637c22a\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.11.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (5.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.43.0->librosa) (3.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechpy\n",
            "  Downloading speechpy-2.4-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from speechpy) (1.21.6)\n",
            "Installing collected packages: speechpy\n",
            "Successfully installed speechpy-2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43p2v4kztIcJ",
        "outputId": "d78ac7ba-3727-43b0-c3ae-ff6a68502c29"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 31.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 77.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 75.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/PL/metadata_train.csv\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train.to_csv(\"train.csv\")\n",
        "test.to_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "kmTAZ_KDq2Xs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cmath import acos\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "# import numpy as np\n",
        "# from torch.utils.data import DataLoader\n",
        "# from infer import phonetic_embedding\n",
        "from help import Atention, wav_norm\n",
        "from char_embedding import tensor_to_text,text_to_tensor\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "# print(data['Wav_path'])\n",
        "sample = data.shape[0]\n",
        "# cols = ['Wav_path', 'Lyric_path']\n",
        "\n",
        "class MDD_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        acoustic_canonical = data\n",
        "        self.n_samples = sample\n",
        "        A = acoustic_canonical['Wav_path']\n",
        "        C = acoustic_canonical['Lyric_path']\n",
        "        B = acoustic_canonical['Lyric_path'] #output\n",
        "        \n",
        "\n",
        "        self.A_data = A \n",
        "        self.C_data = C\n",
        "        self.y_data = B \n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        p = self.A_data[index]\n",
        "        p = p.split(\".\")[0]\n",
        "        base_dir = '/content/drive/MyDrive/raw_song_phonetic/'\n",
        "        p = p + str(\".npy\")\n",
        "        p = np.load(base_dir + str(p))\n",
        "        phonetic = torch.tensor(p)\n",
        "       \n",
        "        linguistic = text_to_tensor(self.C_data[index])\n",
        "        linguistic = torch.tensor(linguistic)\n",
        "        label = text_to_tensor(self.y_data[index])\n",
        "        label = torch.tensor(label)\n",
        "        return phonetic, linguistic, label\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n"
      ],
      "metadata": {
        "id": "sfQTy9LZqs6i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from model import Net\n",
        "# from cProfile import label\n",
        "# from infer import phonetic_embedding\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from phonetic_encoder import Phonetic_encoder\n",
        "from acoustic_encoder import Acoustic_encoder\n",
        "from linguistic_encoder import Linguistic_encoder\n",
        "from char_embedding import text_to_tensor\n",
        "from help import wav_norm, Atention\n",
        "import numpy as np\n",
        "# from help import beam_search_decoding\n",
        "from model import Acoustic_Phonetic_Linguistic\n",
        "# from dataloader import MDD_Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "tokenizer = Wav2Vec2Processor.from_pretrained(\"pretrained_finetuned\")\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "f = open(\"loss.txt\", 'a')\n",
        "MDD = MDD_Dataset()\n",
        "# print(data)\n",
        "net = Acoustic_Phonetic_Linguistic()\n",
        "net.to('cuda')\n",
        "\n",
        "# net = torch.load('/home/tuht/train_wav2vec/MDD_Checkpoint/checkpoint_AdamW_16head_PL.pth')\n",
        "# net = net.to('cpu')\n",
        "train_loader = DataLoader(dataset=MDD,\n",
        "                          batch_size=1,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "\n",
        "\n",
        "ctc_loss = nn.CTCLoss(blank = 95)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
        "optimizer = optim.AdamW(net.parameters(), lr = 0.00001)\n",
        "# optimizer = optim.SGD(net.parameters(), 0.01, momentum = 0.9)\n",
        "# optimizer = torch.load('/home/tuht/train_wav2vec/MDD_Checkpoint/checkpoint_optim.pth')\n",
        "for epoch in range(15):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        phonetic, linguistic, labels = data\n",
        "        # acoustic = torch.tensor(0).to('cuda')\n",
        "        phonetic = phonetic.to('cuda')\n",
        "        linguistic = linguistic.to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(phonetic, linguistic)\n",
        "        outputs = outputs.unsqueeze(1)\n",
        "        input_lengths = outputs.shape\n",
        "        target_lengths = labels.shape\n",
        "        target = labels\n",
        "        input_lengths = [input_lengths[0]]\n",
        "        target_lengths =[target_lengths[1]]\n",
        "        input_lengths = torch.tensor(input_lengths)\n",
        "        target_lengths = torch.tensor(target_lengths)\n",
        "        outputs = (F.log_softmax(outputs, dim=2))\n",
        "        loss = ctc_loss(outputs, labels, input_lengths, target_lengths)\n",
        "        print(loss)\n",
        "        f.write(\"(\" +str(epoch) + \",\" + str(i) + \")\" + \"  loss: \" + str(loss) + \"\\n\") \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    torch.save(net, 'raw_checkpoint.pth' + str(epoch))\n",
        "        \n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "barzAew9tAev",
        "outputId": "dbb1a0fb-7a88-4d8e-9280-9621449838bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/content/drive/MyDrive/PL/linguistic_encoder.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(x, dtype=torch.float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.1496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(43.5408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(42.7137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(88.5856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(69.9664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(33.2243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(30.6333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(38.2603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(81.4362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(36.7661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(12.2739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(13.8104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(44.6873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(54.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(27.0887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(43.5422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(28.0986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(29.1990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(13.6547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.7472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(13.3813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(20.5025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(31.3959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(11.3311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(8.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(11.8407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(40.1999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(14.5743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(18.6425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(37.1832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(10.7169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.6586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(24.4963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(24.3163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(21.2007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(22.7867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(18.8266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(29.9668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(18.5148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(25.9608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(24.6023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(12.3896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(8.3946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(17.4224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(10.7958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(20.2830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(20.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(16.7487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(18.6156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.2382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(17.2761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(16.8082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.0676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(18.6035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(6.6777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(13.8322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(11.4952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(20.3820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(10.3906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(21.0056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.1137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.9095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(11.3005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(5.8931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(9.4924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(12.4603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.8938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(4.6155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.0060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(7.7201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "tensor(6.9212, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    }
  ]
}